{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a2b94577145abacf90b68b286a73c1b5\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "import json\n",
        "\n",
        "json_file_path = 'kaggle.json'\n",
        "\n",
        "with open(json_file_path, 'r') as json_file:\n",
        "    data = json.load(json_file)\n",
        "\n",
        "    print(data['key'])\n",
        "\n",
        "    api = KaggleApi()\n",
        "    api.authenticate()\n",
        "\n",
        "    dataset_name = 'mlg-ulb/creditcardfraud'\n",
        "\n",
        "    api.dataset_download_files(dataset=dataset_name,path='./',unzip=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "CSzjrHCaPjib",
        "outputId": "bdcefd93-ace3-4b00-8696-281fa3bbff95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(284807, 31)"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('creditcard.csv')\n",
        "df.head()\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.        ,  1.19185711,  0.26615071,  0.16648011,  0.44815408,\n",
              "        0.06001765, -0.08236081, -0.07880298,  0.08510165, -0.25542513,\n",
              "       -0.16697441,  1.61272666,  1.06523531,  0.48909502, -0.1437723 ,\n",
              "        0.63555809,  0.46391704, -0.11480466, -0.18336127, -0.14578304,\n",
              "       -0.06908314, -0.22577525, -0.63867195,  0.10128802, -0.33984648,\n",
              "        0.1671704 ,  0.12589453, -0.0089831 ,  0.01472417,  2.69      ,\n",
              "        0.        ])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.values[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7gy1NhWQkcq",
        "outputId": "4da879e1-2578-4b80-91d3-00503f13d964"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Class\n",
              "0    284315\n",
              "1       492\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['Class'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "w0VWEQGJQo46"
      },
      "outputs": [],
      "source": [
        "# df.hist(bins=30,figsize=(30,30))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "fyNY2bmIRD04",
        "outputId": "34009baa-01f2-43d1-fa2a-5459e7664441"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>284807.000000</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>...</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>284807.000000</td>\n",
              "      <td>284807.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>94813.859575</td>\n",
              "      <td>1.168375e-15</td>\n",
              "      <td>3.416908e-16</td>\n",
              "      <td>-1.379537e-15</td>\n",
              "      <td>2.074095e-15</td>\n",
              "      <td>9.604066e-16</td>\n",
              "      <td>1.487313e-15</td>\n",
              "      <td>-5.556467e-16</td>\n",
              "      <td>1.213481e-16</td>\n",
              "      <td>-2.406331e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>1.654067e-16</td>\n",
              "      <td>-3.568593e-16</td>\n",
              "      <td>2.578648e-16</td>\n",
              "      <td>4.473266e-15</td>\n",
              "      <td>5.340915e-16</td>\n",
              "      <td>1.683437e-15</td>\n",
              "      <td>-3.660091e-16</td>\n",
              "      <td>-1.227390e-16</td>\n",
              "      <td>88.349619</td>\n",
              "      <td>0.001727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>47488.145955</td>\n",
              "      <td>1.958696e+00</td>\n",
              "      <td>1.651309e+00</td>\n",
              "      <td>1.516255e+00</td>\n",
              "      <td>1.415869e+00</td>\n",
              "      <td>1.380247e+00</td>\n",
              "      <td>1.332271e+00</td>\n",
              "      <td>1.237094e+00</td>\n",
              "      <td>1.194353e+00</td>\n",
              "      <td>1.098632e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>7.345240e-01</td>\n",
              "      <td>7.257016e-01</td>\n",
              "      <td>6.244603e-01</td>\n",
              "      <td>6.056471e-01</td>\n",
              "      <td>5.212781e-01</td>\n",
              "      <td>4.822270e-01</td>\n",
              "      <td>4.036325e-01</td>\n",
              "      <td>3.300833e-01</td>\n",
              "      <td>250.120109</td>\n",
              "      <td>0.041527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.640751e+01</td>\n",
              "      <td>-7.271573e+01</td>\n",
              "      <td>-4.832559e+01</td>\n",
              "      <td>-5.683171e+00</td>\n",
              "      <td>-1.137433e+02</td>\n",
              "      <td>-2.616051e+01</td>\n",
              "      <td>-4.355724e+01</td>\n",
              "      <td>-7.321672e+01</td>\n",
              "      <td>-1.343407e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.483038e+01</td>\n",
              "      <td>-1.093314e+01</td>\n",
              "      <td>-4.480774e+01</td>\n",
              "      <td>-2.836627e+00</td>\n",
              "      <td>-1.029540e+01</td>\n",
              "      <td>-2.604551e+00</td>\n",
              "      <td>-2.256568e+01</td>\n",
              "      <td>-1.543008e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>54201.500000</td>\n",
              "      <td>-9.203734e-01</td>\n",
              "      <td>-5.985499e-01</td>\n",
              "      <td>-8.903648e-01</td>\n",
              "      <td>-8.486401e-01</td>\n",
              "      <td>-6.915971e-01</td>\n",
              "      <td>-7.682956e-01</td>\n",
              "      <td>-5.540759e-01</td>\n",
              "      <td>-2.086297e-01</td>\n",
              "      <td>-6.430976e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.283949e-01</td>\n",
              "      <td>-5.423504e-01</td>\n",
              "      <td>-1.618463e-01</td>\n",
              "      <td>-3.545861e-01</td>\n",
              "      <td>-3.171451e-01</td>\n",
              "      <td>-3.269839e-01</td>\n",
              "      <td>-7.083953e-02</td>\n",
              "      <td>-5.295979e-02</td>\n",
              "      <td>5.600000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>84692.000000</td>\n",
              "      <td>1.810880e-02</td>\n",
              "      <td>6.548556e-02</td>\n",
              "      <td>1.798463e-01</td>\n",
              "      <td>-1.984653e-02</td>\n",
              "      <td>-5.433583e-02</td>\n",
              "      <td>-2.741871e-01</td>\n",
              "      <td>4.010308e-02</td>\n",
              "      <td>2.235804e-02</td>\n",
              "      <td>-5.142873e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.945017e-02</td>\n",
              "      <td>6.781943e-03</td>\n",
              "      <td>-1.119293e-02</td>\n",
              "      <td>4.097606e-02</td>\n",
              "      <td>1.659350e-02</td>\n",
              "      <td>-5.213911e-02</td>\n",
              "      <td>1.342146e-03</td>\n",
              "      <td>1.124383e-02</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>139320.500000</td>\n",
              "      <td>1.315642e+00</td>\n",
              "      <td>8.037239e-01</td>\n",
              "      <td>1.027196e+00</td>\n",
              "      <td>7.433413e-01</td>\n",
              "      <td>6.119264e-01</td>\n",
              "      <td>3.985649e-01</td>\n",
              "      <td>5.704361e-01</td>\n",
              "      <td>3.273459e-01</td>\n",
              "      <td>5.971390e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.863772e-01</td>\n",
              "      <td>5.285536e-01</td>\n",
              "      <td>1.476421e-01</td>\n",
              "      <td>4.395266e-01</td>\n",
              "      <td>3.507156e-01</td>\n",
              "      <td>2.409522e-01</td>\n",
              "      <td>9.104512e-02</td>\n",
              "      <td>7.827995e-02</td>\n",
              "      <td>77.165000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>172792.000000</td>\n",
              "      <td>2.454930e+00</td>\n",
              "      <td>2.205773e+01</td>\n",
              "      <td>9.382558e+00</td>\n",
              "      <td>1.687534e+01</td>\n",
              "      <td>3.480167e+01</td>\n",
              "      <td>7.330163e+01</td>\n",
              "      <td>1.205895e+02</td>\n",
              "      <td>2.000721e+01</td>\n",
              "      <td>1.559499e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>2.720284e+01</td>\n",
              "      <td>1.050309e+01</td>\n",
              "      <td>2.252841e+01</td>\n",
              "      <td>4.584549e+00</td>\n",
              "      <td>7.519589e+00</td>\n",
              "      <td>3.517346e+00</td>\n",
              "      <td>3.161220e+01</td>\n",
              "      <td>3.384781e+01</td>\n",
              "      <td>25691.160000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                Time            V1            V2            V3            V4  \\\n",
              "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
              "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
              "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
              "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
              "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
              "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
              "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
              "\n",
              "                 V5            V6            V7            V8            V9  \\\n",
              "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
              "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
              "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
              "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
              "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
              "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
              "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
              "\n",
              "       ...           V21           V22           V23           V24  \\\n",
              "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
              "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
              "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
              "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
              "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
              "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
              "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
              "\n",
              "                V25           V26           V27           V28         Amount  \\\n",
              "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
              "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
              "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
              "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
              "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
              "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
              "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
              "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
              "\n",
              "               Class  \n",
              "count  284807.000000  \n",
              "mean        0.001727  \n",
              "std         0.041527  \n",
              "min         0.000000  \n",
              "25%         0.000000  \n",
              "50%         0.000000  \n",
              "75%         0.000000  \n",
              "max         1.000000  \n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "Wyv9A3jmRcIB",
        "outputId": "30e40223-f6b7-4188-d443-db0566e9b815"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>1.783274</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>-0.269825</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000006</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>4.983721</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000006</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>1.418291</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000012</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>0.670579</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Time        V1        V2        V3        V4        V5        V6  \\\n",
              "0  0.000000 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
              "1  0.000000  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
              "2  0.000006 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
              "3  0.000006 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
              "4  0.000012 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
              "\n",
              "         V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
              "0  0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928   \n",
              "1 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
              "2  0.791461  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281   \n",
              "3  0.237609  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
              "4  0.592941 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267   \n",
              "\n",
              "        V25       V26       V27       V28    Amount  Class  \n",
              "0  0.128539 -0.189115  0.133558 -0.021053  1.783274      0  \n",
              "1  0.167170  0.125895 -0.008983  0.014724 -0.269825      0  \n",
              "2 -0.327642 -0.139097 -0.055353 -0.059752  4.983721      0  \n",
              "3  0.647376 -0.221929  0.062723  0.061458  1.418291      0  \n",
              "4 -0.206010  0.502292  0.219422  0.215153  0.670579      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import RobustScaler,MinMaxScaler\n",
        "new_df = df.copy()\n",
        "\n",
        "rob_scaler=RobustScaler().fit(new_df['Amount'].to_numpy().reshape(-1, 1))\n",
        "new_df['Amount'] = rob_scaler.transform(new_df['Amount'].to_numpy().reshape(-1, 1))\n",
        "\n",
        "# time = new_df['Time']\n",
        "# new_df['Time'] = (time - time.min()) / (time.max() - time.min())\n",
        "\n",
        "min_max_scaler=MinMaxScaler().fit(new_df['Time'].to_numpy().reshape(-1, 1))\n",
        "new_df['Time'] = min_max_scaler.transform(new_df['Time'].to_numpy().reshape(-1, 1))\n",
        "\n",
        "\n",
        "# new_df.tail()\n",
        "new_df.head()\n",
        "\n",
        "# new_df.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import joblib\n",
        "# joblib.dump(rob_scaler, './Scaler/robust_scaler.pkl')\n",
        "# joblib.dump(min_max_scaler, './Scaler/min_max.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "HMKr9vDFSsS_",
        "outputId": "ee35a532-8a3e-4f48-c068-e672c509e8bd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>169876</th>\n",
              "      <td>0.693938</td>\n",
              "      <td>-0.611712</td>\n",
              "      <td>-0.769705</td>\n",
              "      <td>-0.149759</td>\n",
              "      <td>-0.224877</td>\n",
              "      <td>2.028577</td>\n",
              "      <td>-2.019887</td>\n",
              "      <td>0.292491</td>\n",
              "      <td>-0.523020</td>\n",
              "      <td>0.358468</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.075208</td>\n",
              "      <td>0.045536</td>\n",
              "      <td>0.380739</td>\n",
              "      <td>0.023440</td>\n",
              "      <td>-2.220686</td>\n",
              "      <td>-0.201146</td>\n",
              "      <td>0.066501</td>\n",
              "      <td>0.221180</td>\n",
              "      <td>-0.282401</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127467</th>\n",
              "      <td>0.453377</td>\n",
              "      <td>-0.814682</td>\n",
              "      <td>1.319219</td>\n",
              "      <td>1.329415</td>\n",
              "      <td>0.027273</td>\n",
              "      <td>-0.284871</td>\n",
              "      <td>-0.653985</td>\n",
              "      <td>0.321552</td>\n",
              "      <td>0.435975</td>\n",
              "      <td>-0.704298</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.128619</td>\n",
              "      <td>-0.368565</td>\n",
              "      <td>0.090660</td>\n",
              "      <td>0.401147</td>\n",
              "      <td>-0.261034</td>\n",
              "      <td>0.080621</td>\n",
              "      <td>0.162427</td>\n",
              "      <td>0.059456</td>\n",
              "      <td>-0.279746</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137900</th>\n",
              "      <td>0.476770</td>\n",
              "      <td>-0.318193</td>\n",
              "      <td>1.118618</td>\n",
              "      <td>0.969864</td>\n",
              "      <td>-0.127052</td>\n",
              "      <td>0.569563</td>\n",
              "      <td>-0.532484</td>\n",
              "      <td>0.706252</td>\n",
              "      <td>-0.064966</td>\n",
              "      <td>-0.463271</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.305402</td>\n",
              "      <td>-0.774704</td>\n",
              "      <td>-0.123884</td>\n",
              "      <td>-0.495687</td>\n",
              "      <td>-0.018148</td>\n",
              "      <td>0.121679</td>\n",
              "      <td>0.249050</td>\n",
              "      <td>0.092516</td>\n",
              "      <td>-0.294977</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21513</th>\n",
              "      <td>0.183556</td>\n",
              "      <td>-1.328271</td>\n",
              "      <td>1.018378</td>\n",
              "      <td>1.775426</td>\n",
              "      <td>-1.574193</td>\n",
              "      <td>-0.117696</td>\n",
              "      <td>-0.457733</td>\n",
              "      <td>0.681867</td>\n",
              "      <td>-0.031641</td>\n",
              "      <td>0.383872</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.220815</td>\n",
              "      <td>-0.419013</td>\n",
              "      <td>-0.239197</td>\n",
              "      <td>0.009967</td>\n",
              "      <td>0.232829</td>\n",
              "      <td>0.814177</td>\n",
              "      <td>0.098797</td>\n",
              "      <td>-0.004273</td>\n",
              "      <td>-0.084119</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134700</th>\n",
              "      <td>0.468326</td>\n",
              "      <td>1.276712</td>\n",
              "      <td>0.617120</td>\n",
              "      <td>-0.578014</td>\n",
              "      <td>0.879173</td>\n",
              "      <td>0.061706</td>\n",
              "      <td>-1.472002</td>\n",
              "      <td>0.373692</td>\n",
              "      <td>-0.287204</td>\n",
              "      <td>-0.084482</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.160161</td>\n",
              "      <td>-0.430404</td>\n",
              "      <td>-0.076738</td>\n",
              "      <td>0.258708</td>\n",
              "      <td>0.552170</td>\n",
              "      <td>0.370701</td>\n",
              "      <td>-0.034255</td>\n",
              "      <td>0.041709</td>\n",
              "      <td>-0.296793</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Time        V1        V2        V3        V4        V5        V6  \\\n",
              "169876  0.693938 -0.611712 -0.769705 -0.149759 -0.224877  2.028577 -2.019887   \n",
              "127467  0.453377 -0.814682  1.319219  1.329415  0.027273 -0.284871 -0.653985   \n",
              "137900  0.476770 -0.318193  1.118618  0.969864 -0.127052  0.569563 -0.532484   \n",
              "21513   0.183556 -1.328271  1.018378  1.775426 -1.574193 -0.117696 -0.457733   \n",
              "134700  0.468326  1.276712  0.617120 -0.578014  0.879173  0.061706 -1.472002   \n",
              "\n",
              "              V7        V8        V9  ...       V21       V22       V23  \\\n",
              "169876  0.292491 -0.523020  0.358468  ... -0.075208  0.045536  0.380739   \n",
              "127467  0.321552  0.435975 -0.704298  ... -0.128619 -0.368565  0.090660   \n",
              "137900  0.706252 -0.064966 -0.463271  ... -0.305402 -0.774704 -0.123884   \n",
              "21513   0.681867 -0.031641  0.383872  ... -0.220815 -0.419013 -0.239197   \n",
              "134700  0.373692 -0.287204 -0.084482  ... -0.160161 -0.430404 -0.076738   \n",
              "\n",
              "             V24       V25       V26       V27       V28    Amount  Class  \n",
              "169876  0.023440 -2.220686 -0.201146  0.066501  0.221180 -0.282401      0  \n",
              "127467  0.401147 -0.261034  0.080621  0.162427  0.059456 -0.279746      0  \n",
              "137900 -0.495687 -0.018148  0.121679  0.249050  0.092516 -0.294977      0  \n",
              "21513   0.009967  0.232829  0.814177  0.098797 -0.004273 -0.084119      0  \n",
              "134700  0.258708  0.552170  0.370701 -0.034255  0.041709 -0.296793      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_df = new_df.sample(frac=1, random_state=1)\n",
        "new_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdFdQP3JUlFF"
      },
      "source": [
        "Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_SnMFqK3aPkH"
      },
      "outputs": [],
      "source": [
        "# %pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "o8B7BB08UjO1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-10-14 09:31:06.664053: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-10-14 09:31:06.899071: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-10-14 09:31:06.899122: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-10-14 09:31:06.899166: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-10-14 09:31:06.957212: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-10-14 09:31:06.958006: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-14 09:31:11.135034: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "import datetime\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,InputLayer,BatchNormalization\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "checkpoint = ModelCheckpoint('Neural_network', save_best_only=True)\n",
        "\n",
        "def save_model(model):\n",
        "  joblib.dump(model, './Models/model_{}.pkl'.format(datetime.datetime.now().strftime(\"%f\")))\n",
        "\n",
        "def neural_net_predictions(model, x):\n",
        "  return (model.predict(x).flatten() > 0.5).astype(int)\n",
        "\n",
        "def report(x_valid,y_valid,model):\n",
        "  print(classification_report(y_valid, neural_net_predictions(model, x_valid), target_names=['Not Fraud', 'Fraud']))\n",
        "\n",
        "def create_logistic_regression_model(x_train,y_train):\n",
        "  logistic_model=LogisticRegression(solver='lbfgs', max_iter=400)\n",
        "  logistic_model.fit(x_train,y_train)\n",
        "  print(\"Score of model: {}\".format(logistic_model.score(x_train,y_train)))\n",
        "  return logistic_model\n",
        "\n",
        "def create_random_forest(x_train,y_train):\n",
        "  random_forest = RandomForestClassifier(max_depth=2, n_jobs=-1)\n",
        "  random_forest.fit(x_train, y_train)\n",
        "  return random_forest\n",
        "\n",
        "def create_gradient_boosting(x_train,y_train):\n",
        "  gradient_boosting = GradientBoostingClassifier(n_estimators=50, learning_rate=1.0, max_depth=1, random_state=0)\n",
        "  gradient_boosting.fit(x_train, y_train)\n",
        "  return gradient_boosting\n",
        "\n",
        "def create_support_vector_machine(x_train,y_train):\n",
        "  support_vector_machine = LinearSVC(class_weight='balanced',max_iter=2000)\n",
        "  support_vector_machine.fit(x_train, y_train)\n",
        "  return support_vector_machine\n",
        "\n",
        "def create_neural_network(x_train):\n",
        "  shallow_nn=Sequential()\n",
        "  shallow_nn.add(InputLayer((x_train.shape[1],)))\n",
        "  shallow_nn.add(Dense(2, 'relu'))\n",
        "  shallow_nn.add(BatchNormalization())\n",
        "  shallow_nn.add(Dense(1, 'sigmoid'))\n",
        "\n",
        "  shallow_nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return shallow_nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gL2R2xDUXXR"
      },
      "source": [
        "# Creating model with imbalanced dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "Vfz1AnO6THMo",
        "outputId": "e8abf4c4-3998-476c-cd22-0584c11fd39c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set size: (227845, 30) samples\n",
            "Validation set size: (28481, 30) samples\n",
            "Test set size: (28481, 30) samples\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>190142</th>\n",
              "      <td>0.744855</td>\n",
              "      <td>1.995920</td>\n",
              "      <td>-0.188109</td>\n",
              "      <td>-2.012022</td>\n",
              "      <td>0.148846</td>\n",
              "      <td>0.746843</td>\n",
              "      <td>-0.322789</td>\n",
              "      <td>0.444843</td>\n",
              "      <td>-0.235136</td>\n",
              "      <td>0.053315</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.039745</td>\n",
              "      <td>0.012924</td>\n",
              "      <td>0.092354</td>\n",
              "      <td>-0.016985</td>\n",
              "      <td>0.272453</td>\n",
              "      <td>0.239177</td>\n",
              "      <td>0.532860</td>\n",
              "      <td>-0.112135</td>\n",
              "      <td>-0.075215</td>\n",
              "      <td>0.474394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100377</th>\n",
              "      <td>0.390614</td>\n",
              "      <td>1.082013</td>\n",
              "      <td>-0.283593</td>\n",
              "      <td>0.695923</td>\n",
              "      <td>0.321769</td>\n",
              "      <td>-0.647056</td>\n",
              "      <td>-0.187080</td>\n",
              "      <td>-0.213180</td>\n",
              "      <td>0.010876</td>\n",
              "      <td>0.621063</td>\n",
              "      <td>...</td>\n",
              "      <td>0.038563</td>\n",
              "      <td>-0.316975</td>\n",
              "      <td>-0.826320</td>\n",
              "      <td>0.134753</td>\n",
              "      <td>0.135106</td>\n",
              "      <td>0.047205</td>\n",
              "      <td>0.548807</td>\n",
              "      <td>-0.031429</td>\n",
              "      <td>0.022642</td>\n",
              "      <td>0.597918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254900</th>\n",
              "      <td>0.908416</td>\n",
              "      <td>-0.164343</td>\n",
              "      <td>1.238717</td>\n",
              "      <td>-0.928374</td>\n",
              "      <td>-0.633338</td>\n",
              "      <td>0.905294</td>\n",
              "      <td>-0.436320</td>\n",
              "      <td>0.706147</td>\n",
              "      <td>0.219601</td>\n",
              "      <td>-0.262998</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.026587</td>\n",
              "      <td>0.365896</td>\n",
              "      <td>1.199292</td>\n",
              "      <td>-0.141703</td>\n",
              "      <td>0.090812</td>\n",
              "      <td>-0.620967</td>\n",
              "      <td>-0.210063</td>\n",
              "      <td>0.383667</td>\n",
              "      <td>0.261436</td>\n",
              "      <td>-0.244673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30542</th>\n",
              "      <td>0.208198</td>\n",
              "      <td>0.641922</td>\n",
              "      <td>-0.763976</td>\n",
              "      <td>0.810805</td>\n",
              "      <td>1.492406</td>\n",
              "      <td>-0.809403</td>\n",
              "      <td>0.505133</td>\n",
              "      <td>-0.189771</td>\n",
              "      <td>0.211449</td>\n",
              "      <td>0.503381</td>\n",
              "      <td>...</td>\n",
              "      <td>0.293828</td>\n",
              "      <td>0.188034</td>\n",
              "      <td>0.366043</td>\n",
              "      <td>-0.271572</td>\n",
              "      <td>0.273772</td>\n",
              "      <td>0.479763</td>\n",
              "      <td>-0.301794</td>\n",
              "      <td>0.032824</td>\n",
              "      <td>0.055178</td>\n",
              "      <td>2.893314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178479</th>\n",
              "      <td>0.715566</td>\n",
              "      <td>1.876897</td>\n",
              "      <td>-0.058575</td>\n",
              "      <td>-1.487466</td>\n",
              "      <td>1.184822</td>\n",
              "      <td>0.434595</td>\n",
              "      <td>-0.524684</td>\n",
              "      <td>0.392677</td>\n",
              "      <td>-0.293299</td>\n",
              "      <td>0.123953</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.023298</td>\n",
              "      <td>0.308670</td>\n",
              "      <td>0.833960</td>\n",
              "      <td>-0.064232</td>\n",
              "      <td>0.632489</td>\n",
              "      <td>0.331684</td>\n",
              "      <td>-0.461074</td>\n",
              "      <td>-0.011141</td>\n",
              "      <td>-0.029971</td>\n",
              "      <td>0.950185</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Time        V1        V2        V3        V4        V5        V6  \\\n",
              "190142  0.744855  1.995920 -0.188109 -2.012022  0.148846  0.746843 -0.322789   \n",
              "100377  0.390614  1.082013 -0.283593  0.695923  0.321769 -0.647056 -0.187080   \n",
              "254900  0.908416 -0.164343  1.238717 -0.928374 -0.633338  0.905294 -0.436320   \n",
              "30542   0.208198  0.641922 -0.763976  0.810805  1.492406 -0.809403  0.505133   \n",
              "178479  0.715566  1.876897 -0.058575 -1.487466  1.184822  0.434595 -0.524684   \n",
              "\n",
              "              V7        V8        V9  ...       V20       V21       V22  \\\n",
              "190142  0.444843 -0.235136  0.053315  ... -0.039745  0.012924  0.092354   \n",
              "100377 -0.213180  0.010876  0.621063  ...  0.038563 -0.316975 -0.826320   \n",
              "254900  0.706147  0.219601 -0.262998  ... -0.026587  0.365896  1.199292   \n",
              "30542  -0.189771  0.211449  0.503381  ...  0.293828  0.188034  0.366043   \n",
              "178479  0.392677 -0.293299  0.123953  ... -0.023298  0.308670  0.833960   \n",
              "\n",
              "             V23       V24       V25       V26       V27       V28    Amount  \n",
              "190142 -0.016985  0.272453  0.239177  0.532860 -0.112135 -0.075215  0.474394  \n",
              "100377  0.134753  0.135106  0.047205  0.548807 -0.031429  0.022642  0.597918  \n",
              "254900 -0.141703  0.090812 -0.620967 -0.210063  0.383667  0.261436 -0.244673  \n",
              "30542  -0.271572  0.273772  0.479763 -0.301794  0.032824  0.055178  2.893314  \n",
              "178479 -0.064232  0.632489  0.331684 -0.461074 -0.011141 -0.029971  0.950185  \n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X=new_df.drop(['Class'], axis=1)\n",
        "y=new_df['Class']\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Training set size: {X_train.shape} samples\")\n",
        "print(f\"Validation set size: {X_valid.shape} samples\")\n",
        "print(f\"Test set size: {X_test.shape} samples\")\n",
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3YyOMMvUVCU",
        "outputId": "27a1a9d8-0495-4848-f708-9229eb706037"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score of model: 0.9991441550176655\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Not Fraud       1.00      1.00      1.00     28436\n",
            "       Fraud       0.90      0.58      0.70        45\n",
            "\n",
            "    accuracy                           1.00     28481\n",
            "   macro avg       0.95      0.79      0.85     28481\n",
            "weighted avg       1.00      1.00      1.00     28481\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lgm=create_logistic_regression_model(X_train,y_train)\n",
        "report(X_valid,y_valid,lgm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRtKq6-aczk5",
        "outputId": "45b87106-caf0-43a0-b652-fe7f0fce9c55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "7101/7121 [============================>.] - ETA: 0s - loss: 0.0553 - accuracy: 0.9830INFO:tensorflow:Assets written to: Neural_network/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Neural_network/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7121/7121 [==============================] - 12s 2ms/step - loss: 0.0551 - accuracy: 0.9831 - val_loss: 0.0031 - val_accuracy: 0.9995\n",
            "Epoch 2/5\n",
            "7082/7121 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9992INFO:tensorflow:Assets written to: Neural_network/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Neural_network/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7121/7121 [==============================] - 11s 2ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0030 - val_accuracy: 0.9994\n",
            "Epoch 3/5\n",
            "7105/7121 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9993INFO:tensorflow:Assets written to: Neural_network/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Neural_network/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7121/7121 [==============================] - 11s 2ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.0026 - val_accuracy: 0.9995\n",
            "Epoch 4/5\n",
            "7121/7121 [==============================] - 11s 1ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.0032 - val_accuracy: 0.9994\n",
            "Epoch 5/5\n",
            "7093/7121 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9993INFO:tensorflow:Assets written to: Neural_network/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Neural_network/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7121/7121 [==============================] - 11s 1ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.0025 - val_accuracy: 0.9995\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f04e2fdf070>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nn=create_neural_network(X_train)\n",
        "nn.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=5, callbacks=checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAg7WqAlg-Cl",
        "outputId": "89bff947-7128-4d21-de9b-cf83860a81c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "131/891 [===>..........................] - ETA: 0s"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "891/891 [==============================] - 1s 1ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Not Fraud       1.00      1.00      1.00     28436\n",
            "       Fraud       0.83      0.84      0.84        45\n",
            "\n",
            "    accuracy                           1.00     28481\n",
            "   macro avg       0.91      0.92      0.92     28481\n",
            "weighted avg       1.00      1.00      1.00     28481\n",
            "\n"
          ]
        }
      ],
      "source": [
        "report(X_valid,y_valid,nn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOYIe4sKkq05",
        "outputId": "a224f1d1-9566-4c91-8a25-cd743d4c7703"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Not Fraud       1.00      1.00      1.00     28436\n",
            "       Fraud       0.89      0.53      0.67        45\n",
            "\n",
            "    accuracy                           1.00     28481\n",
            "   macro avg       0.94      0.77      0.83     28481\n",
            "weighted avg       1.00      1.00      1.00     28481\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rf=create_random_forest(X_train,y_train)\n",
        "report(X_valid,y_valid,rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOyHfyaOlklo",
        "outputId": "c3450a66-48fb-42ff-c43c-bc54ad518275"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Not Fraud       1.00      1.00      1.00     28436\n",
            "       Fraud       0.72      0.69      0.70        45\n",
            "\n",
            "    accuracy                           1.00     28481\n",
            "   macro avg       0.86      0.84      0.85     28481\n",
            "weighted avg       1.00      1.00      1.00     28481\n",
            "\n"
          ]
        }
      ],
      "source": [
        "gbc=create_gradient_boosting(X_train,y_train)\n",
        "report(X_valid,y_valid,gbc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3n6PfhzsWmU",
        "outputId": "7ea8fa0a-b6eb-4933-f321-e243503e2d58"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/codespace/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Not Fraud       1.00      1.00      1.00     28436\n",
            "       Fraud       0.73      0.80      0.77        45\n",
            "\n",
            "    accuracy                           1.00     28481\n",
            "   macro avg       0.87      0.90      0.88     28481\n",
            "weighted avg       1.00      1.00      1.00     28481\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/codespace/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "svc=create_support_vector_machine(X_train,y_train)\n",
        "report(X_valid,y_valid,svc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOWMeeM8vPNM"
      },
      "source": [
        "# Creating model with balanced dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qaca7a2ivqOz",
        "outputId": "6464900c-d96f-4fad-deeb-16de75cffce4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Class\n",
              "1    492\n",
              "0    492\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fraud_df=new_df[new_df['Class']==1]\n",
        "not_fraud_df=new_df[new_df['Class']==0]\n",
        "\n",
        "# print(fraud_df.shape)\n",
        "# print(not_fraud_df.shape)\n",
        "\n",
        "balanced_df=pd.concat([fraud_df,not_fraud_df.sample(len(fraud_df),random_state=1)])\n",
        "balanced_df['Class'].value_counts()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "DsNvDqotwa27",
        "outputId": "61495e90-2677-4c31-b084-cd39eaa63c6d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18372</th>\n",
              "      <td>0.170309</td>\n",
              "      <td>-1.762593</td>\n",
              "      <td>0.256143</td>\n",
              "      <td>1.683125</td>\n",
              "      <td>-1.279233</td>\n",
              "      <td>-1.902762</td>\n",
              "      <td>1.004210</td>\n",
              "      <td>-1.009748</td>\n",
              "      <td>-2.432546</td>\n",
              "      <td>0.458860</td>\n",
              "      <td>...</td>\n",
              "      <td>2.493579</td>\n",
              "      <td>0.320829</td>\n",
              "      <td>-0.535481</td>\n",
              "      <td>0.499401</td>\n",
              "      <td>-0.915196</td>\n",
              "      <td>-0.423434</td>\n",
              "      <td>0.107049</td>\n",
              "      <td>0.175922</td>\n",
              "      <td>2.906449</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96341</th>\n",
              "      <td>0.380388</td>\n",
              "      <td>1.227614</td>\n",
              "      <td>-0.668974</td>\n",
              "      <td>-0.271785</td>\n",
              "      <td>-0.589440</td>\n",
              "      <td>-0.604795</td>\n",
              "      <td>-0.350285</td>\n",
              "      <td>-0.486365</td>\n",
              "      <td>-0.010809</td>\n",
              "      <td>-0.794944</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.026055</td>\n",
              "      <td>-0.295255</td>\n",
              "      <td>-0.180459</td>\n",
              "      <td>-0.436539</td>\n",
              "      <td>0.494649</td>\n",
              "      <td>-0.283738</td>\n",
              "      <td>-0.001128</td>\n",
              "      <td>0.035075</td>\n",
              "      <td>1.062111</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248296</th>\n",
              "      <td>0.890522</td>\n",
              "      <td>-0.613696</td>\n",
              "      <td>3.698772</td>\n",
              "      <td>-5.534941</td>\n",
              "      <td>5.620486</td>\n",
              "      <td>1.649263</td>\n",
              "      <td>-2.335145</td>\n",
              "      <td>-0.907188</td>\n",
              "      <td>0.706362</td>\n",
              "      <td>-3.747646</td>\n",
              "      <td>...</td>\n",
              "      <td>0.319261</td>\n",
              "      <td>-0.471379</td>\n",
              "      <td>-0.075890</td>\n",
              "      <td>-0.667909</td>\n",
              "      <td>-0.642848</td>\n",
              "      <td>0.070600</td>\n",
              "      <td>0.488410</td>\n",
              "      <td>0.292345</td>\n",
              "      <td>-0.307413</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>264328</th>\n",
              "      <td>0.933932</td>\n",
              "      <td>-0.011624</td>\n",
              "      <td>0.640413</td>\n",
              "      <td>0.868046</td>\n",
              "      <td>-0.505279</td>\n",
              "      <td>0.261938</td>\n",
              "      <td>0.223098</td>\n",
              "      <td>0.239049</td>\n",
              "      <td>0.150877</td>\n",
              "      <td>0.225142</td>\n",
              "      <td>...</td>\n",
              "      <td>0.069401</td>\n",
              "      <td>0.268024</td>\n",
              "      <td>0.261459</td>\n",
              "      <td>0.683742</td>\n",
              "      <td>-1.567901</td>\n",
              "      <td>-0.816674</td>\n",
              "      <td>0.185781</td>\n",
              "      <td>0.283021</td>\n",
              "      <td>-0.272619</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208904</th>\n",
              "      <td>0.794730</td>\n",
              "      <td>-0.679341</td>\n",
              "      <td>1.217389</td>\n",
              "      <td>-0.316778</td>\n",
              "      <td>-1.086725</td>\n",
              "      <td>0.855349</td>\n",
              "      <td>-0.980760</td>\n",
              "      <td>0.970589</td>\n",
              "      <td>0.133116</td>\n",
              "      <td>-0.357671</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.083048</td>\n",
              "      <td>-0.137032</td>\n",
              "      <td>-0.238920</td>\n",
              "      <td>-0.617244</td>\n",
              "      <td>0.039020</td>\n",
              "      <td>-0.081848</td>\n",
              "      <td>0.234633</td>\n",
              "      <td>0.128382</td>\n",
              "      <td>-0.307273</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Time        V1        V2        V3        V4        V5        V6  \\\n",
              "18372   0.170309 -1.762593  0.256143  1.683125 -1.279233 -1.902762  1.004210   \n",
              "96341   0.380388  1.227614 -0.668974 -0.271785 -0.589440 -0.604795 -0.350285   \n",
              "248296  0.890522 -0.613696  3.698772 -5.534941  5.620486  1.649263 -2.335145   \n",
              "264328  0.933932 -0.011624  0.640413  0.868046 -0.505279  0.261938  0.223098   \n",
              "208904  0.794730 -0.679341  1.217389 -0.316778 -1.086725  0.855349 -0.980760   \n",
              "\n",
              "              V7        V8        V9  ...       V21       V22       V23  \\\n",
              "18372  -1.009748 -2.432546  0.458860  ...  2.493579  0.320829 -0.535481   \n",
              "96341  -0.486365 -0.010809 -0.794944  ... -0.026055 -0.295255 -0.180459   \n",
              "248296 -0.907188  0.706362 -3.747646  ...  0.319261 -0.471379 -0.075890   \n",
              "264328  0.239049  0.150877  0.225142  ...  0.069401  0.268024  0.261459   \n",
              "208904  0.970589  0.133116 -0.357671  ... -0.083048 -0.137032 -0.238920   \n",
              "\n",
              "             V24       V25       V26       V27       V28    Amount  Class  \n",
              "18372   0.499401 -0.915196 -0.423434  0.107049  0.175922  2.906449      0  \n",
              "96341  -0.436539  0.494649 -0.283738 -0.001128  0.035075  1.062111      1  \n",
              "248296 -0.667909 -0.642848  0.070600  0.488410  0.292345 -0.307413      1  \n",
              "264328  0.683742 -1.567901 -0.816674  0.185781  0.283021 -0.272619      0  \n",
              "208904 -0.617244  0.039020 -0.081848  0.234633  0.128382 -0.307273      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "balanced_df = balanced_df.sample(frac=1, random_state=1)\n",
        "balanced_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "xPIxjJc6vX8T",
        "outputId": "e92bce04-de08-48e7-88cc-7e3bf6bbb08c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set size: (787, 30) samples\n",
            "Validation set size: (98, 30) samples\n",
            "Test set size: (99, 30) samples\n",
            "Class\n",
            "1    394\n",
            "0    393\n",
            "Name: count, dtype: int64\n",
            "Class\n",
            "0    54\n",
            "1    45\n",
            "Name: count, dtype: int64\n",
            "Class\n",
            "1    53\n",
            "0    45\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>243020</th>\n",
              "      <td>0.878258</td>\n",
              "      <td>-2.054024</td>\n",
              "      <td>1.936722</td>\n",
              "      <td>-0.915965</td>\n",
              "      <td>-2.751863</td>\n",
              "      <td>0.072058</td>\n",
              "      <td>-0.766585</td>\n",
              "      <td>0.093632</td>\n",
              "      <td>1.285874</td>\n",
              "      <td>-0.361733</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.091999</td>\n",
              "      <td>-0.186646</td>\n",
              "      <td>-0.796626</td>\n",
              "      <td>0.025251</td>\n",
              "      <td>0.360288</td>\n",
              "      <td>0.136603</td>\n",
              "      <td>0.355476</td>\n",
              "      <td>0.055981</td>\n",
              "      <td>0.091078</td>\n",
              "      <td>-0.293440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218802</th>\n",
              "      <td>0.818690</td>\n",
              "      <td>-2.569928</td>\n",
              "      <td>-0.136741</td>\n",
              "      <td>-1.129399</td>\n",
              "      <td>-0.849203</td>\n",
              "      <td>2.523548</td>\n",
              "      <td>-1.161707</td>\n",
              "      <td>1.594990</td>\n",
              "      <td>-0.625916</td>\n",
              "      <td>-0.028604</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.084042</td>\n",
              "      <td>-0.466621</td>\n",
              "      <td>0.308128</td>\n",
              "      <td>0.374118</td>\n",
              "      <td>0.177536</td>\n",
              "      <td>1.722167</td>\n",
              "      <td>0.408659</td>\n",
              "      <td>0.099027</td>\n",
              "      <td>-0.432163</td>\n",
              "      <td>0.053518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70101</th>\n",
              "      <td>0.310830</td>\n",
              "      <td>1.130941</td>\n",
              "      <td>0.274630</td>\n",
              "      <td>0.542070</td>\n",
              "      <td>0.937542</td>\n",
              "      <td>-0.109606</td>\n",
              "      <td>-0.084768</td>\n",
              "      <td>-0.026067</td>\n",
              "      <td>0.081163</td>\n",
              "      <td>-0.298001</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.114830</td>\n",
              "      <td>-0.141155</td>\n",
              "      <td>-0.403601</td>\n",
              "      <td>0.107511</td>\n",
              "      <td>-0.017835</td>\n",
              "      <td>0.281269</td>\n",
              "      <td>-0.620396</td>\n",
              "      <td>0.039441</td>\n",
              "      <td>0.018328</td>\n",
              "      <td>-0.167819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>280149</th>\n",
              "      <td>0.980086</td>\n",
              "      <td>-0.676143</td>\n",
              "      <td>1.126366</td>\n",
              "      <td>-2.213700</td>\n",
              "      <td>0.468308</td>\n",
              "      <td>-1.120541</td>\n",
              "      <td>-0.003346</td>\n",
              "      <td>-2.234739</td>\n",
              "      <td>1.210158</td>\n",
              "      <td>-0.652250</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247968</td>\n",
              "      <td>0.751826</td>\n",
              "      <td>0.834108</td>\n",
              "      <td>0.190944</td>\n",
              "      <td>0.032070</td>\n",
              "      <td>-0.739695</td>\n",
              "      <td>0.471111</td>\n",
              "      <td>0.385107</td>\n",
              "      <td>0.194361</td>\n",
              "      <td>0.780968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63772</th>\n",
              "      <td>0.294354</td>\n",
              "      <td>-7.260160</td>\n",
              "      <td>-0.748718</td>\n",
              "      <td>-4.235954</td>\n",
              "      <td>2.197864</td>\n",
              "      <td>-1.154121</td>\n",
              "      <td>-0.504497</td>\n",
              "      <td>-1.798552</td>\n",
              "      <td>2.899145</td>\n",
              "      <td>-0.081777</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.066162</td>\n",
              "      <td>-0.031561</td>\n",
              "      <td>-0.370800</td>\n",
              "      <td>-2.122943</td>\n",
              "      <td>-1.117761</td>\n",
              "      <td>-0.338351</td>\n",
              "      <td>-0.203432</td>\n",
              "      <td>0.605844</td>\n",
              "      <td>-0.550336</td>\n",
              "      <td>-0.293440</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Time        V1        V2        V3        V4        V5        V6  \\\n",
              "243020  0.878258 -2.054024  1.936722 -0.915965 -2.751863  0.072058 -0.766585   \n",
              "218802  0.818690 -2.569928 -0.136741 -1.129399 -0.849203  2.523548 -1.161707   \n",
              "70101   0.310830  1.130941  0.274630  0.542070  0.937542 -0.109606 -0.084768   \n",
              "280149  0.980086 -0.676143  1.126366 -2.213700  0.468308 -1.120541 -0.003346   \n",
              "63772   0.294354 -7.260160 -0.748718 -4.235954  2.197864 -1.154121 -0.504497   \n",
              "\n",
              "              V7        V8        V9  ...       V20       V21       V22  \\\n",
              "243020  0.093632  1.285874 -0.361733  ... -0.091999 -0.186646 -0.796626   \n",
              "218802  1.594990 -0.625916 -0.028604  ... -1.084042 -0.466621  0.308128   \n",
              "70101  -0.026067  0.081163 -0.298001  ... -0.114830 -0.141155 -0.403601   \n",
              "280149 -2.234739  1.210158 -0.652250  ...  0.247968  0.751826  0.834108   \n",
              "63772  -1.798552  2.899145 -0.081777  ... -0.066162 -0.031561 -0.370800   \n",
              "\n",
              "             V23       V24       V25       V26       V27       V28    Amount  \n",
              "243020  0.025251  0.360288  0.136603  0.355476  0.055981  0.091078 -0.293440  \n",
              "218802  0.374118  0.177536  1.722167  0.408659  0.099027 -0.432163  0.053518  \n",
              "70101   0.107511 -0.017835  0.281269 -0.620396  0.039441  0.018328 -0.167819  \n",
              "280149  0.190944  0.032070 -0.739695  0.471111  0.385107  0.194361  0.780968  \n",
              "63772  -2.122943 -1.117761 -0.338351 -0.203432  0.605844 -0.550336 -0.293440  \n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X=balanced_df.drop(['Class'], axis=1)\n",
        "y=balanced_df['Class']\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Training set size: {X_train.shape} samples\")\n",
        "print(f\"Validation set size: {X_valid.shape} samples\")\n",
        "print(f\"Test set size: {X_test.shape} samples\")\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())\n",
        "print(y_valid.value_counts())\n",
        "\n",
        "\n",
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41RpQ1nSxCfT",
        "outputId": "c4503e37-f5ea-44c6-d25b-06b283f92a74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score of model: 0.9529860228716646\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Not Fraud       0.87      1.00      0.93        45\n",
            "       Fraud       1.00      0.87      0.93        53\n",
            "\n",
            "    accuracy                           0.93        98\n",
            "   macro avg       0.93      0.93      0.93        98\n",
            "weighted avg       0.94      0.93      0.93        98\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lgm_b=create_logistic_regression_model(X_train,y_train)\n",
        "report(X_valid,y_valid,lgm_b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "NABP5ib6xfVm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25/25 [==============================] - 1s 9ms/step - loss: 0.8038 - accuracy: 0.4498 - val_loss: 0.7459 - val_accuracy: 0.4796\n",
            "Epoch 2/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.6708 - accuracy: 0.5807 - val_loss: 0.6249 - val_accuracy: 0.6633\n",
            "Epoch 3/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.6056 - accuracy: 0.6709 - val_loss: 0.5700 - val_accuracy: 0.7347\n",
            "Epoch 4/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5729 - accuracy: 0.7230 - val_loss: 0.5438 - val_accuracy: 0.7449\n",
            "Epoch 5/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.7611 - val_loss: 0.5242 - val_accuracy: 0.7653\n",
            "Epoch 6/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.7776 - val_loss: 0.5108 - val_accuracy: 0.7857\n",
            "Epoch 7/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5200 - accuracy: 0.8005 - val_loss: 0.5003 - val_accuracy: 0.8163\n",
            "Epoch 8/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5026 - accuracy: 0.7992 - val_loss: 0.4896 - val_accuracy: 0.8265\n",
            "Epoch 9/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.8234 - val_loss: 0.4784 - val_accuracy: 0.8265\n",
            "Epoch 10/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4821 - accuracy: 0.8107 - val_loss: 0.4626 - val_accuracy: 0.8265\n",
            "Epoch 11/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.8475 - val_loss: 0.4477 - val_accuracy: 0.8571\n",
            "Epoch 12/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.8475 - val_loss: 0.4346 - val_accuracy: 0.8571\n",
            "Epoch 13/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.8564 - val_loss: 0.4210 - val_accuracy: 0.8571\n",
            "Epoch 14/40\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8767 - val_loss: 0.4084 - val_accuracy: 0.8571\n",
            "Epoch 15/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4036 - accuracy: 0.8717 - val_loss: 0.3968 - val_accuracy: 0.8571\n",
            "Epoch 16/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3955 - accuracy: 0.8717 - val_loss: 0.3835 - val_accuracy: 0.8673\n",
            "Epoch 17/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3800 - accuracy: 0.8729 - val_loss: 0.3703 - val_accuracy: 0.8776\n",
            "Epoch 18/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3660 - accuracy: 0.8882 - val_loss: 0.3571 - val_accuracy: 0.8776\n",
            "Epoch 19/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3486 - accuracy: 0.9009 - val_loss: 0.3461 - val_accuracy: 0.8776\n",
            "Epoch 20/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.3478 - accuracy: 0.8933 - val_loss: 0.3352 - val_accuracy: 0.8878\n",
            "Epoch 21/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3287 - accuracy: 0.9022 - val_loss: 0.3244 - val_accuracy: 0.8878\n",
            "Epoch 22/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3160 - accuracy: 0.9072 - val_loss: 0.3141 - val_accuracy: 0.8878\n",
            "Epoch 23/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.3128 - accuracy: 0.9111 - val_loss: 0.3039 - val_accuracy: 0.8878\n",
            "Epoch 24/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2978 - accuracy: 0.9212 - val_loss: 0.2950 - val_accuracy: 0.8878\n",
            "Epoch 25/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2954 - accuracy: 0.9136 - val_loss: 0.2855 - val_accuracy: 0.8878\n",
            "Epoch 26/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2746 - accuracy: 0.9212 - val_loss: 0.2773 - val_accuracy: 0.8878\n",
            "Epoch 27/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2676 - accuracy: 0.9276 - val_loss: 0.2678 - val_accuracy: 0.8980\n",
            "Epoch 28/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2612 - accuracy: 0.9212 - val_loss: 0.2586 - val_accuracy: 0.8980\n",
            "Epoch 29/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2540 - accuracy: 0.9250 - val_loss: 0.2501 - val_accuracy: 0.8980\n",
            "Epoch 30/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2506 - accuracy: 0.9276 - val_loss: 0.2417 - val_accuracy: 0.9082\n",
            "Epoch 31/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.9187 - val_loss: 0.2331 - val_accuracy: 0.9082\n",
            "Epoch 32/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2390 - accuracy: 0.9314 - val_loss: 0.2267 - val_accuracy: 0.9082\n",
            "Epoch 33/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2276 - accuracy: 0.9390 - val_loss: 0.2225 - val_accuracy: 0.9082\n",
            "Epoch 34/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2270 - accuracy: 0.9301 - val_loss: 0.2192 - val_accuracy: 0.9082\n",
            "Epoch 35/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2376 - accuracy: 0.9238 - val_loss: 0.2169 - val_accuracy: 0.9082\n",
            "Epoch 36/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2160 - accuracy: 0.9454 - val_loss: 0.2144 - val_accuracy: 0.9082\n",
            "Epoch 37/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2089 - accuracy: 0.9403 - val_loss: 0.2134 - val_accuracy: 0.9082\n",
            "Epoch 38/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2231 - accuracy: 0.9301 - val_loss: 0.2131 - val_accuracy: 0.9082\n",
            "Epoch 39/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2051 - accuracy: 0.9428 - val_loss: 0.2145 - val_accuracy: 0.9082\n",
            "Epoch 40/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2010 - accuracy: 0.9441 - val_loss: 0.2141 - val_accuracy: 0.9082\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f0533febe20>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nn_b=create_neural_network(X_train)\n",
        "nn_b.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=40, callbacks=checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "tCLy4nS5yOo2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1994 - accuracy: 0.9428 - val_loss: 0.2154 - val_accuracy: 0.9082\n",
            "Epoch 2/40\n",
            " 1/25 [>.............................] - ETA: 0s - loss: 0.1529 - accuracy: 0.9688"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2071 - accuracy: 0.9314 - val_loss: 0.2166 - val_accuracy: 0.9082\n",
            "Epoch 3/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1933 - accuracy: 0.9492 - val_loss: 0.2195 - val_accuracy: 0.9082\n",
            "Epoch 4/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1806 - accuracy: 0.9466 - val_loss: 0.2217 - val_accuracy: 0.9082\n",
            "Epoch 5/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1917 - accuracy: 0.9390 - val_loss: 0.2280 - val_accuracy: 0.9082\n",
            "Epoch 6/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1899 - accuracy: 0.9428 - val_loss: 0.2303 - val_accuracy: 0.9184\n",
            "Epoch 7/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1796 - accuracy: 0.9454 - val_loss: 0.2318 - val_accuracy: 0.9286\n",
            "Epoch 8/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1818 - accuracy: 0.9428 - val_loss: 0.2369 - val_accuracy: 0.9286\n",
            "Epoch 9/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1903 - accuracy: 0.9441 - val_loss: 0.2387 - val_accuracy: 0.9286\n",
            "Epoch 10/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1909 - accuracy: 0.9428 - val_loss: 0.2399 - val_accuracy: 0.9388\n",
            "Epoch 11/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1825 - accuracy: 0.9403 - val_loss: 0.2420 - val_accuracy: 0.9388\n",
            "Epoch 12/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1833 - accuracy: 0.9441 - val_loss: 0.2441 - val_accuracy: 0.9388\n",
            "Epoch 13/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1885 - accuracy: 0.9352 - val_loss: 0.2480 - val_accuracy: 0.9388\n",
            "Epoch 14/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1734 - accuracy: 0.9416 - val_loss: 0.2495 - val_accuracy: 0.9388\n",
            "Epoch 15/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1872 - accuracy: 0.9441 - val_loss: 0.2532 - val_accuracy: 0.9388\n",
            "Epoch 16/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1701 - accuracy: 0.9441 - val_loss: 0.2556 - val_accuracy: 0.9388\n",
            "Epoch 17/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1658 - accuracy: 0.9517 - val_loss: 0.2571 - val_accuracy: 0.9388\n",
            "Epoch 18/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1763 - accuracy: 0.9365 - val_loss: 0.2577 - val_accuracy: 0.9388\n",
            "Epoch 19/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1762 - accuracy: 0.9416 - val_loss: 0.2594 - val_accuracy: 0.9388\n",
            "Epoch 20/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.9377 - val_loss: 0.2607 - val_accuracy: 0.9388\n",
            "Epoch 21/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1695 - accuracy: 0.9416 - val_loss: 0.2646 - val_accuracy: 0.9388\n",
            "Epoch 22/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1572 - accuracy: 0.9479 - val_loss: 0.2652 - val_accuracy: 0.9388\n",
            "Epoch 23/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1706 - accuracy: 0.9327 - val_loss: 0.2653 - val_accuracy: 0.9388\n",
            "Epoch 24/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1638 - accuracy: 0.9479 - val_loss: 0.2668 - val_accuracy: 0.9388\n",
            "Epoch 25/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1743 - accuracy: 0.9454 - val_loss: 0.2722 - val_accuracy: 0.9388\n",
            "Epoch 26/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1614 - accuracy: 0.9466 - val_loss: 0.2752 - val_accuracy: 0.9388\n",
            "Epoch 27/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1703 - accuracy: 0.9416 - val_loss: 0.2787 - val_accuracy: 0.9388\n",
            "Epoch 28/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1602 - accuracy: 0.9390 - val_loss: 0.2809 - val_accuracy: 0.9388\n",
            "Epoch 29/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1637 - accuracy: 0.9441 - val_loss: 0.2818 - val_accuracy: 0.9388\n",
            "Epoch 30/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1711 - accuracy: 0.9365 - val_loss: 0.2814 - val_accuracy: 0.9388\n",
            "Epoch 31/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1574 - accuracy: 0.9466 - val_loss: 0.2839 - val_accuracy: 0.9388\n",
            "Epoch 32/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1699 - accuracy: 0.9352 - val_loss: 0.2887 - val_accuracy: 0.9388\n",
            "Epoch 33/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1533 - accuracy: 0.9492 - val_loss: 0.2878 - val_accuracy: 0.9388\n",
            "Epoch 34/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1605 - accuracy: 0.9428 - val_loss: 0.2894 - val_accuracy: 0.9388\n",
            "Epoch 35/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1553 - accuracy: 0.9428 - val_loss: 0.2929 - val_accuracy: 0.9388\n",
            "Epoch 36/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1739 - accuracy: 0.9428 - val_loss: 0.2965 - val_accuracy: 0.9388\n",
            "Epoch 37/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1601 - accuracy: 0.9441 - val_loss: 0.2949 - val_accuracy: 0.9388\n",
            "Epoch 38/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1597 - accuracy: 0.9454 - val_loss: 0.2965 - val_accuracy: 0.9388\n",
            "Epoch 39/40\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1661 - accuracy: 0.9403 - val_loss: 0.2982 - val_accuracy: 0.9388\n",
            "Epoch 40/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1505 - accuracy: 0.9441 - val_loss: 0.2980 - val_accuracy: 0.9388\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f04eff83940>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nn_b.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=40, callbacks=checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czisHHQEycAQ",
        "outputId": "1ecab712-0260-477d-c16f-8de15aeba57c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 1ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Not Fraud       0.88      1.00      0.94        45\n",
            "       Fraud       1.00      0.89      0.94        53\n",
            "\n",
            "    accuracy                           0.94        98\n",
            "   macro avg       0.94      0.94      0.94        98\n",
            "weighted avg       0.95      0.94      0.94        98\n",
            "\n"
          ]
        }
      ],
      "source": [
        "report(X_valid,y_valid,nn_b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RxARq32yxil",
        "outputId": "4e900f38-8a25-438d-bbc5-f3cf3fce502b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Not Fraud       0.80      1.00      0.89        45\n",
            "       Fraud       1.00      0.79      0.88        53\n",
            "\n",
            "    accuracy                           0.89        98\n",
            "   macro avg       0.90      0.90      0.89        98\n",
            "weighted avg       0.91      0.89      0.89        98\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rf_b=create_random_forest(X_train,y_train)\n",
        "report(X_valid,y_valid,rf_b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAnI8w5py4s4",
        "outputId": "a22ed4d5-712b-4937-bf3f-4b3d6feb4b67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Not Fraud       0.87      1.00      0.93        45\n",
            "       Fraud       1.00      0.87      0.93        53\n",
            "\n",
            "    accuracy                           0.93        98\n",
            "   macro avg       0.93      0.93      0.93        98\n",
            "weighted avg       0.94      0.93      0.93        98\n",
            "\n"
          ]
        }
      ],
      "source": [
        "gbc_b=create_gradient_boosting(X_train,y_train)\n",
        "report(X_valid,y_valid,gbc_b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS_wWKblzEt3",
        "outputId": "28f9e55b-cfb4-4260-c83b-53f9a8898361"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Not Fraud       0.87      1.00      0.93        45\n",
            "       Fraud       1.00      0.87      0.93        53\n",
            "\n",
            "    accuracy                           0.93        98\n",
            "   macro avg       0.93      0.93      0.93        98\n",
            "weighted avg       0.94      0.93      0.93        98\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/codespace/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n",
            "/home/codespace/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "svc_b=create_support_vector_machine(X_train,y_train)\n",
        "report(X_valid,y_valid,svc_b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZRxYgW62Fhw"
      },
      "source": [
        "# Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "cWFeynet1_tZ"
      },
      "outputs": [],
      "source": [
        "# save_model(svc_b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "loading and predicting "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "model = joblib.load(\"./Models/model_101296.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4462.0</td>\n",
              "      <td>-2.303350</td>\n",
              "      <td>1.759247</td>\n",
              "      <td>-0.359745</td>\n",
              "      <td>2.330243</td>\n",
              "      <td>-0.821628</td>\n",
              "      <td>-0.075788</td>\n",
              "      <td>0.562320</td>\n",
              "      <td>-0.399147</td>\n",
              "      <td>-0.238253</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.294166</td>\n",
              "      <td>-0.932391</td>\n",
              "      <td>0.172726</td>\n",
              "      <td>-0.087330</td>\n",
              "      <td>-0.156114</td>\n",
              "      <td>-0.542628</td>\n",
              "      <td>0.039566</td>\n",
              "      <td>-0.153029</td>\n",
              "      <td>239.93</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>472.0</td>\n",
              "      <td>-3.043541</td>\n",
              "      <td>-3.157307</td>\n",
              "      <td>1.088463</td>\n",
              "      <td>2.288644</td>\n",
              "      <td>1.359805</td>\n",
              "      <td>-1.064823</td>\n",
              "      <td>0.325574</td>\n",
              "      <td>-0.067794</td>\n",
              "      <td>-0.270953</td>\n",
              "      <td>...</td>\n",
              "      <td>0.661696</td>\n",
              "      <td>0.435477</td>\n",
              "      <td>1.375966</td>\n",
              "      <td>-0.293803</td>\n",
              "      <td>0.279798</td>\n",
              "      <td>-0.145362</td>\n",
              "      <td>-0.252773</td>\n",
              "      <td>0.035764</td>\n",
              "      <td>529.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>406.0</td>\n",
              "      <td>-2.312227</td>\n",
              "      <td>1.951992</td>\n",
              "      <td>-1.609851</td>\n",
              "      <td>3.997906</td>\n",
              "      <td>-0.522188</td>\n",
              "      <td>-1.426545</td>\n",
              "      <td>-2.537387</td>\n",
              "      <td>1.391657</td>\n",
              "      <td>-2.770089</td>\n",
              "      <td>...</td>\n",
              "      <td>0.517232</td>\n",
              "      <td>-0.035049</td>\n",
              "      <td>-0.465211</td>\n",
              "      <td>0.320198</td>\n",
              "      <td>0.044519</td>\n",
              "      <td>0.177840</td>\n",
              "      <td>0.261145</td>\n",
              "      <td>-0.143276</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Time        V1        V2        V3        V4        V5        V6  \\\n",
              "2  4462.0 -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788   \n",
              "1   472.0 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823   \n",
              "4     0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
              "0   406.0 -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545   \n",
              "3     0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
              "5     1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
              "\n",
              "         V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
              "2  0.562320 -0.399147 -0.238253  ... -0.294166 -0.932391  0.172726 -0.087330   \n",
              "1  0.325574 -0.067794 -0.270953  ...  0.661696  0.435477  1.375966 -0.293803   \n",
              "4 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
              "0 -2.537387  1.391657 -2.770089  ...  0.517232 -0.035049 -0.465211  0.320198   \n",
              "3  0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928   \n",
              "5  0.791461  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281   \n",
              "\n",
              "        V25       V26       V27       V28  Amount  Class  \n",
              "2 -0.156114 -0.542628  0.039566 -0.153029  239.93      1  \n",
              "1  0.279798 -0.145362 -0.252773  0.035764  529.00      1  \n",
              "4  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
              "0  0.044519  0.177840  0.261145 -0.143276    0.00      1  \n",
              "3  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
              "5 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
              "\n",
              "[6 rows x 31 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('creditcard.csv')\n",
        "new_df=df[df['Class']==1].head(3)\n",
        "new_df=pd.concat([new_df,df.query('Class==0').iloc[:3,:]],ignore_index=True)\n",
        "new_df = new_df.sample(frac=1, random_state=1)\n",
        "new_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import json\n",
        "\n",
        "temp=new_df.drop('Class',axis=1).values\n",
        "new_columns=['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
        "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
        "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']\n",
        "newp_df=pd.DataFrame(temp,columns=new_columns)\n",
        "\n",
        "with open('Testing.JSON', 'w') as outfile:\n",
        "       json.dump({\"data\":newp_df.values.tolist()},outfile)\n",
        "# if not scaling the prediction will be wrong\n",
        "\n",
        "robb_scaler = joblib.load('./Scaler/robust_scaler.pkl')\n",
        "min_maxb_scaler = joblib.load('./Scaler/min_max.pkl')\n",
        "\n",
        "newp_df['Amount']=robb_scaler.transform(newp_df['Amount'].values.reshape(-1,1))\n",
        "newp_df['Time']=min_maxb_scaler.transform(newp_df['Time'].values.reshape(-1,1))\n",
        "\n",
        "# self not use the paramters from trained and test dataset such as mean and std\n",
        "# with open('Testing.JSON', 'w') as outfile:\n",
        "#        json.dump(newp_df.values.tolist(),outfile)\n",
        "# new_df.values[0].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 0, 1, 0, 0])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# print(new_np)\n",
        "model.predict(newp_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
