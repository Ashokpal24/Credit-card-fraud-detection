{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a2b94577145abacf90b68b286a73c1b5\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "import json\n",
        "\n",
        "json_file_path = 'kaggle.json'\n",
        "\n",
        "with open(json_file_path, 'r') as json_file:\n",
        "    data = json.load(json_file)\n",
        "\n",
        "    print(data['key'])\n",
        "\n",
        "    api = KaggleApi()\n",
        "    api.authenticate()\n",
        "\n",
        "    dataset_name = 'mlg-ulb/creditcardfraud'\n",
        "\n",
        "    api.dataset_download_files(dataset=dataset_name,path='./',unzip=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "CSzjrHCaPjib",
        "outputId": "bdcefd93-ace3-4b00-8696-281fa3bbff95"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
              "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
              "\n",
              "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
              "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
              "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
              "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
              "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
              "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
              "\n",
              "        V26       V27       V28  Amount  Class  \n",
              "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
              "1  0.125895 -0.008983  0.014724    2.69      0  \n",
              "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
              "3 -0.221929  0.062723  0.061458  123.50      0  \n",
              "4  0.502292  0.219422  0.215153   69.99      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('creditcard.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7gy1NhWQkcq",
        "outputId": "4da879e1-2578-4b80-91d3-00503f13d964"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Class\n",
              "0    284315\n",
              "1       492\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['Class'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "w0VWEQGJQo46"
      },
      "outputs": [],
      "source": [
        "# df.hist(bins=30,figsize=(30,30))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "fyNY2bmIRD04",
        "outputId": "34009baa-01f2-43d1-fa2a-5459e7664441"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>284807.000000</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>...</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>284807.000000</td>\n",
              "      <td>284807.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>94813.859575</td>\n",
              "      <td>1.168375e-15</td>\n",
              "      <td>3.416908e-16</td>\n",
              "      <td>-1.379537e-15</td>\n",
              "      <td>2.074095e-15</td>\n",
              "      <td>9.604066e-16</td>\n",
              "      <td>1.487313e-15</td>\n",
              "      <td>-5.556467e-16</td>\n",
              "      <td>1.213481e-16</td>\n",
              "      <td>-2.406331e-15</td>\n",
              "      <td>...</td>\n",
              "      <td>1.654067e-16</td>\n",
              "      <td>-3.568593e-16</td>\n",
              "      <td>2.578648e-16</td>\n",
              "      <td>4.473266e-15</td>\n",
              "      <td>5.340915e-16</td>\n",
              "      <td>1.683437e-15</td>\n",
              "      <td>-3.660091e-16</td>\n",
              "      <td>-1.227390e-16</td>\n",
              "      <td>88.349619</td>\n",
              "      <td>0.001727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>47488.145955</td>\n",
              "      <td>1.958696e+00</td>\n",
              "      <td>1.651309e+00</td>\n",
              "      <td>1.516255e+00</td>\n",
              "      <td>1.415869e+00</td>\n",
              "      <td>1.380247e+00</td>\n",
              "      <td>1.332271e+00</td>\n",
              "      <td>1.237094e+00</td>\n",
              "      <td>1.194353e+00</td>\n",
              "      <td>1.098632e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>7.345240e-01</td>\n",
              "      <td>7.257016e-01</td>\n",
              "      <td>6.244603e-01</td>\n",
              "      <td>6.056471e-01</td>\n",
              "      <td>5.212781e-01</td>\n",
              "      <td>4.822270e-01</td>\n",
              "      <td>4.036325e-01</td>\n",
              "      <td>3.300833e-01</td>\n",
              "      <td>250.120109</td>\n",
              "      <td>0.041527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.640751e+01</td>\n",
              "      <td>-7.271573e+01</td>\n",
              "      <td>-4.832559e+01</td>\n",
              "      <td>-5.683171e+00</td>\n",
              "      <td>-1.137433e+02</td>\n",
              "      <td>-2.616051e+01</td>\n",
              "      <td>-4.355724e+01</td>\n",
              "      <td>-7.321672e+01</td>\n",
              "      <td>-1.343407e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.483038e+01</td>\n",
              "      <td>-1.093314e+01</td>\n",
              "      <td>-4.480774e+01</td>\n",
              "      <td>-2.836627e+00</td>\n",
              "      <td>-1.029540e+01</td>\n",
              "      <td>-2.604551e+00</td>\n",
              "      <td>-2.256568e+01</td>\n",
              "      <td>-1.543008e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>54201.500000</td>\n",
              "      <td>-9.203734e-01</td>\n",
              "      <td>-5.985499e-01</td>\n",
              "      <td>-8.903648e-01</td>\n",
              "      <td>-8.486401e-01</td>\n",
              "      <td>-6.915971e-01</td>\n",
              "      <td>-7.682956e-01</td>\n",
              "      <td>-5.540759e-01</td>\n",
              "      <td>-2.086297e-01</td>\n",
              "      <td>-6.430976e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.283949e-01</td>\n",
              "      <td>-5.423504e-01</td>\n",
              "      <td>-1.618463e-01</td>\n",
              "      <td>-3.545861e-01</td>\n",
              "      <td>-3.171451e-01</td>\n",
              "      <td>-3.269839e-01</td>\n",
              "      <td>-7.083953e-02</td>\n",
              "      <td>-5.295979e-02</td>\n",
              "      <td>5.600000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>84692.000000</td>\n",
              "      <td>1.810880e-02</td>\n",
              "      <td>6.548556e-02</td>\n",
              "      <td>1.798463e-01</td>\n",
              "      <td>-1.984653e-02</td>\n",
              "      <td>-5.433583e-02</td>\n",
              "      <td>-2.741871e-01</td>\n",
              "      <td>4.010308e-02</td>\n",
              "      <td>2.235804e-02</td>\n",
              "      <td>-5.142873e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.945017e-02</td>\n",
              "      <td>6.781943e-03</td>\n",
              "      <td>-1.119293e-02</td>\n",
              "      <td>4.097606e-02</td>\n",
              "      <td>1.659350e-02</td>\n",
              "      <td>-5.213911e-02</td>\n",
              "      <td>1.342146e-03</td>\n",
              "      <td>1.124383e-02</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>139320.500000</td>\n",
              "      <td>1.315642e+00</td>\n",
              "      <td>8.037239e-01</td>\n",
              "      <td>1.027196e+00</td>\n",
              "      <td>7.433413e-01</td>\n",
              "      <td>6.119264e-01</td>\n",
              "      <td>3.985649e-01</td>\n",
              "      <td>5.704361e-01</td>\n",
              "      <td>3.273459e-01</td>\n",
              "      <td>5.971390e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>1.863772e-01</td>\n",
              "      <td>5.285536e-01</td>\n",
              "      <td>1.476421e-01</td>\n",
              "      <td>4.395266e-01</td>\n",
              "      <td>3.507156e-01</td>\n",
              "      <td>2.409522e-01</td>\n",
              "      <td>9.104512e-02</td>\n",
              "      <td>7.827995e-02</td>\n",
              "      <td>77.165000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>172792.000000</td>\n",
              "      <td>2.454930e+00</td>\n",
              "      <td>2.205773e+01</td>\n",
              "      <td>9.382558e+00</td>\n",
              "      <td>1.687534e+01</td>\n",
              "      <td>3.480167e+01</td>\n",
              "      <td>7.330163e+01</td>\n",
              "      <td>1.205895e+02</td>\n",
              "      <td>2.000721e+01</td>\n",
              "      <td>1.559499e+01</td>\n",
              "      <td>...</td>\n",
              "      <td>2.720284e+01</td>\n",
              "      <td>1.050309e+01</td>\n",
              "      <td>2.252841e+01</td>\n",
              "      <td>4.584549e+00</td>\n",
              "      <td>7.519589e+00</td>\n",
              "      <td>3.517346e+00</td>\n",
              "      <td>3.161220e+01</td>\n",
              "      <td>3.384781e+01</td>\n",
              "      <td>25691.160000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows Ã— 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                Time            V1            V2            V3            V4  \\\n",
              "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
              "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
              "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
              "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
              "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
              "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
              "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
              "\n",
              "                 V5            V6            V7            V8            V9  \\\n",
              "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
              "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
              "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
              "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
              "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
              "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
              "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
              "\n",
              "       ...           V21           V22           V23           V24  \\\n",
              "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
              "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
              "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
              "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
              "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
              "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
              "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
              "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
              "\n",
              "                V25           V26           V27           V28         Amount  \\\n",
              "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
              "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
              "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
              "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
              "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
              "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
              "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
              "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
              "\n",
              "               Class  \n",
              "count  284807.000000  \n",
              "mean        0.001727  \n",
              "std         0.041527  \n",
              "min         0.000000  \n",
              "25%         0.000000  \n",
              "50%         0.000000  \n",
              "75%         0.000000  \n",
              "max         1.000000  \n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "Wyv9A3jmRcIB",
        "outputId": "30e40223-f6b7-4188-d443-db0566e9b815"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>1.783274</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>-0.269825</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000006</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>4.983721</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000006</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>1.418291</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000012</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>0.670579</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Time        V1        V2        V3        V4        V5        V6  \\\n",
              "0  0.000000 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
              "1  0.000000  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
              "2  0.000006 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
              "3  0.000006 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
              "4  0.000012 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
              "\n",
              "         V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
              "0  0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928   \n",
              "1 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
              "2  0.791461  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281   \n",
              "3  0.237609  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
              "4  0.592941 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267   \n",
              "\n",
              "        V25       V26       V27       V28    Amount  Class  \n",
              "0  0.128539 -0.189115  0.133558 -0.021053  1.783274      0  \n",
              "1  0.167170  0.125895 -0.008983  0.014724 -0.269825      0  \n",
              "2 -0.327642 -0.139097 -0.055353 -0.059752  4.983721      0  \n",
              "3  0.647376 -0.221929  0.062723  0.061458  1.418291      0  \n",
              "4 -0.206010  0.502292  0.219422  0.215153  0.670579      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "new_df = df.copy()\n",
        "\n",
        "new_df['Amount'] = RobustScaler().fit_transform(new_df['Amount'].to_numpy().reshape(-1, 1))\n",
        "\n",
        "time = new_df['Time']\n",
        "new_df['Time'] = (time - time.min()) / (time.max() - time.min())\n",
        "\n",
        "new_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "HMKr9vDFSsS_",
        "outputId": "ee35a532-8a3e-4f48-c068-e672c509e8bd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>79394</th>\n",
              "      <td>0.335698</td>\n",
              "      <td>1.297904</td>\n",
              "      <td>0.043872</td>\n",
              "      <td>0.009486</td>\n",
              "      <td>0.247843</td>\n",
              "      <td>-0.006953</td>\n",
              "      <td>-0.041165</td>\n",
              "      <td>-0.181796</td>\n",
              "      <td>0.113385</td>\n",
              "      <td>0.124404</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.302000</td>\n",
              "      <td>-0.987028</td>\n",
              "      <td>0.000210</td>\n",
              "      <td>-0.889473</td>\n",
              "      <td>0.285051</td>\n",
              "      <td>0.155191</td>\n",
              "      <td>-0.045627</td>\n",
              "      <td>-0.006632</td>\n",
              "      <td>-0.279746</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234060</th>\n",
              "      <td>0.855427</td>\n",
              "      <td>-3.454268</td>\n",
              "      <td>0.939446</td>\n",
              "      <td>-3.998022</td>\n",
              "      <td>0.364151</td>\n",
              "      <td>-0.042234</td>\n",
              "      <td>-2.524825</td>\n",
              "      <td>-0.306520</td>\n",
              "      <td>0.924521</td>\n",
              "      <td>0.150267</td>\n",
              "      <td>...</td>\n",
              "      <td>0.126650</td>\n",
              "      <td>0.817265</td>\n",
              "      <td>-0.648714</td>\n",
              "      <td>0.219970</td>\n",
              "      <td>0.234361</td>\n",
              "      <td>1.019397</td>\n",
              "      <td>-0.198642</td>\n",
              "      <td>-0.176424</td>\n",
              "      <td>-0.118773</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88697</th>\n",
              "      <td>0.360260</td>\n",
              "      <td>-0.524164</td>\n",
              "      <td>-0.516659</td>\n",
              "      <td>2.560737</td>\n",
              "      <td>0.030273</td>\n",
              "      <td>-1.595964</td>\n",
              "      <td>0.899283</td>\n",
              "      <td>-0.397618</td>\n",
              "      <td>0.197104</td>\n",
              "      <td>-0.587595</td>\n",
              "      <td>...</td>\n",
              "      <td>0.219752</td>\n",
              "      <td>0.722938</td>\n",
              "      <td>-0.035164</td>\n",
              "      <td>-0.034385</td>\n",
              "      <td>0.301716</td>\n",
              "      <td>0.189905</td>\n",
              "      <td>0.114639</td>\n",
              "      <td>0.098380</td>\n",
              "      <td>1.788584</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195482</th>\n",
              "      <td>0.758600</td>\n",
              "      <td>1.913035</td>\n",
              "      <td>0.444965</td>\n",
              "      <td>-2.482750</td>\n",
              "      <td>0.600412</td>\n",
              "      <td>1.180905</td>\n",
              "      <td>-0.248702</td>\n",
              "      <td>0.135888</td>\n",
              "      <td>0.030653</td>\n",
              "      <td>0.471372</td>\n",
              "      <td>...</td>\n",
              "      <td>0.185071</td>\n",
              "      <td>0.859973</td>\n",
              "      <td>0.038084</td>\n",
              "      <td>-1.242674</td>\n",
              "      <td>0.036824</td>\n",
              "      <td>-0.003165</td>\n",
              "      <td>0.074703</td>\n",
              "      <td>-0.003435</td>\n",
              "      <td>-0.293440</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78321</th>\n",
              "      <td>0.332625</td>\n",
              "      <td>-6.423197</td>\n",
              "      <td>1.072629</td>\n",
              "      <td>-3.820238</td>\n",
              "      <td>-0.269845</td>\n",
              "      <td>-4.125205</td>\n",
              "      <td>-0.690805</td>\n",
              "      <td>-0.196968</td>\n",
              "      <td>2.840871</td>\n",
              "      <td>-0.307457</td>\n",
              "      <td>...</td>\n",
              "      <td>0.011082</td>\n",
              "      <td>0.109586</td>\n",
              "      <td>-0.041425</td>\n",
              "      <td>0.576822</td>\n",
              "      <td>-0.291755</td>\n",
              "      <td>0.837947</td>\n",
              "      <td>-0.077805</td>\n",
              "      <td>-0.788987</td>\n",
              "      <td>3.259973</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Time        V1        V2        V3        V4        V5        V6  \\\n",
              "79394   0.335698  1.297904  0.043872  0.009486  0.247843 -0.006953 -0.041165   \n",
              "234060  0.855427 -3.454268  0.939446 -3.998022  0.364151 -0.042234 -2.524825   \n",
              "88697   0.360260 -0.524164 -0.516659  2.560737  0.030273 -1.595964  0.899283   \n",
              "195482  0.758600  1.913035  0.444965 -2.482750  0.600412  1.180905 -0.248702   \n",
              "78321   0.332625 -6.423197  1.072629 -3.820238 -0.269845 -4.125205 -0.690805   \n",
              "\n",
              "              V7        V8        V9  ...       V21       V22       V23  \\\n",
              "79394  -0.181796  0.113385  0.124404  ... -0.302000 -0.987028  0.000210   \n",
              "234060 -0.306520  0.924521  0.150267  ...  0.126650  0.817265 -0.648714   \n",
              "88697  -0.397618  0.197104 -0.587595  ...  0.219752  0.722938 -0.035164   \n",
              "195482  0.135888  0.030653  0.471372  ...  0.185071  0.859973  0.038084   \n",
              "78321  -0.196968  2.840871 -0.307457  ...  0.011082  0.109586 -0.041425   \n",
              "\n",
              "             V24       V25       V26       V27       V28    Amount  Class  \n",
              "79394  -0.889473  0.285051  0.155191 -0.045627 -0.006632 -0.279746      0  \n",
              "234060  0.219970  0.234361  1.019397 -0.198642 -0.176424 -0.118773      0  \n",
              "88697  -0.034385  0.301716  0.189905  0.114639  0.098380  1.788584      0  \n",
              "195482 -1.242674  0.036824 -0.003165  0.074703 -0.003435 -0.293440      0  \n",
              "78321   0.576822 -0.291755  0.837947 -0.077805 -0.788987  3.259973      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_df = new_df.sample(frac=1, random_state=1)\n",
        "new_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdFdQP3JUlFF"
      },
      "source": [
        "Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_SnMFqK3aPkH"
      },
      "outputs": [],
      "source": [
        "# %pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "o8B7BB08UjO1"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import datetime\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,InputLayer,BatchNormalization\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "checkpoint = ModelCheckpoint('Neural_network', save_best_only=True)\n",
        "\n",
        "def save_model(model):\n",
        "  joblib.dump(model, 'model_{}.pkl'.format(datetime.datetime.now().strftime(\"%f\")))\n",
        "\n",
        "def neural_net_predictions(model, x):\n",
        "  return (model.predict(x).flatten() > 0.5).astype(int)\n",
        "\n",
        "def report(x_valid,y_valid,model):\n",
        "  print(classification_report(y_valid, neural_net_predictions(model, x_valid), target_names=['Not Fraud', 'Fraud']))\n",
        "\n",
        "def create_logistic_regression_model(x_train,y_train):\n",
        "  logistic_model=LogisticRegression(solver='lbfgs', max_iter=400)\n",
        "  logistic_model.fit(x_train,y_train)\n",
        "  print(\"Score of model: {}\".format(logistic_model.score(x_train,y_train)))\n",
        "  return logistic_model\n",
        "\n",
        "def create_random_forest(x_train,y_train):\n",
        "  random_forest = RandomForestClassifier(max_depth=2, n_jobs=-1)\n",
        "  random_forest.fit(x_train, y_train)\n",
        "  return random_forest\n",
        "\n",
        "def create_gradient_boosting(x_train,y_train):\n",
        "  gradient_boosting = GradientBoostingClassifier(n_estimators=50, learning_rate=1.0, max_depth=1, random_state=0)\n",
        "  gradient_boosting.fit(x_train, y_train)\n",
        "  return gradient_boosting\n",
        "\n",
        "def create_support_vector_machine(x_train,y_train):\n",
        "  support_vector_machine = LinearSVC(class_weight='balanced',max_iter=2000)\n",
        "  support_vector_machine.fit(x_train, y_train)\n",
        "  return support_vector_machine\n",
        "\n",
        "def create_neural_network(x_train):\n",
        "  shallow_nn=Sequential()\n",
        "  shallow_nn.add(InputLayer((x_train.shape[1],)))\n",
        "  shallow_nn.add(Dense(2, 'relu'))\n",
        "  shallow_nn.add(BatchNormalization())\n",
        "  shallow_nn.add(Dense(1, 'sigmoid'))\n",
        "\n",
        "  shallow_nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return shallow_nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gL2R2xDUXXR"
      },
      "source": [
        "# Creating model with imbalanced dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "Vfz1AnO6THMo",
        "outputId": "e8abf4c4-3998-476c-cd22-0584c11fd39c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set size: (227845, 30) samples\n",
            "Validation set size: (28481, 30) samples\n",
            "Test set size: (28481, 30) samples\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>28038</th>\n",
              "      <td>0.201526</td>\n",
              "      <td>-0.403018</td>\n",
              "      <td>-0.046406</td>\n",
              "      <td>0.708998</td>\n",
              "      <td>-2.814695</td>\n",
              "      <td>-0.356957</td>\n",
              "      <td>-0.296305</td>\n",
              "      <td>-0.162918</td>\n",
              "      <td>-0.031772</td>\n",
              "      <td>-1.893162</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.099445</td>\n",
              "      <td>-0.277103</td>\n",
              "      <td>-0.255063</td>\n",
              "      <td>-0.219751</td>\n",
              "      <td>-1.051576</td>\n",
              "      <td>-0.071472</td>\n",
              "      <td>-0.318397</td>\n",
              "      <td>0.505580</td>\n",
              "      <td>0.254396</td>\n",
              "      <td>-0.097813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284627</th>\n",
              "      <td>0.999005</td>\n",
              "      <td>0.101542</td>\n",
              "      <td>0.843042</td>\n",
              "      <td>-0.241025</td>\n",
              "      <td>-1.031457</td>\n",
              "      <td>1.201955</td>\n",
              "      <td>0.002530</td>\n",
              "      <td>0.935481</td>\n",
              "      <td>-0.018998</td>\n",
              "      <td>-0.333071</td>\n",
              "      <td>...</td>\n",
              "      <td>0.066461</td>\n",
              "      <td>-0.290075</td>\n",
              "      <td>-0.644184</td>\n",
              "      <td>-0.123625</td>\n",
              "      <td>-1.370601</td>\n",
              "      <td>-0.309764</td>\n",
              "      <td>0.202960</td>\n",
              "      <td>0.247188</td>\n",
              "      <td>0.074998</td>\n",
              "      <td>-0.271362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237646</th>\n",
              "      <td>0.864253</td>\n",
              "      <td>-0.056813</td>\n",
              "      <td>0.712313</td>\n",
              "      <td>0.873197</td>\n",
              "      <td>-0.661824</td>\n",
              "      <td>-0.444252</td>\n",
              "      <td>-0.180090</td>\n",
              "      <td>-0.895637</td>\n",
              "      <td>-2.745349</td>\n",
              "      <td>0.150701</td>\n",
              "      <td>...</td>\n",
              "      <td>0.585094</td>\n",
              "      <td>-1.500237</td>\n",
              "      <td>-0.234961</td>\n",
              "      <td>0.076958</td>\n",
              "      <td>0.038061</td>\n",
              "      <td>0.451758</td>\n",
              "      <td>-0.266409</td>\n",
              "      <td>0.100812</td>\n",
              "      <td>0.267906</td>\n",
              "      <td>-0.111786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234811</th>\n",
              "      <td>0.857256</td>\n",
              "      <td>-0.102864</td>\n",
              "      <td>0.707906</td>\n",
              "      <td>-0.671513</td>\n",
              "      <td>0.228768</td>\n",
              "      <td>-0.036591</td>\n",
              "      <td>0.574874</td>\n",
              "      <td>0.686402</td>\n",
              "      <td>-0.053521</td>\n",
              "      <td>-2.011999</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.277009</td>\n",
              "      <td>-0.257745</td>\n",
              "      <td>-0.037853</td>\n",
              "      <td>-0.134715</td>\n",
              "      <td>0.243289</td>\n",
              "      <td>-0.568439</td>\n",
              "      <td>0.678426</td>\n",
              "      <td>-0.304572</td>\n",
              "      <td>-0.142747</td>\n",
              "      <td>1.047998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88119</th>\n",
              "      <td>0.358784</td>\n",
              "      <td>-0.859762</td>\n",
              "      <td>1.300495</td>\n",
              "      <td>1.143530</td>\n",
              "      <td>0.472301</td>\n",
              "      <td>-0.888677</td>\n",
              "      <td>0.550030</td>\n",
              "      <td>-2.072273</td>\n",
              "      <td>-5.232143</td>\n",
              "      <td>-0.467182</td>\n",
              "      <td>...</td>\n",
              "      <td>1.225091</td>\n",
              "      <td>-2.859073</td>\n",
              "      <td>-0.121434</td>\n",
              "      <td>0.072207</td>\n",
              "      <td>0.364112</td>\n",
              "      <td>1.127124</td>\n",
              "      <td>0.293169</td>\n",
              "      <td>-0.048896</td>\n",
              "      <td>0.202355</td>\n",
              "      <td>-0.028086</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Time        V1        V2        V3        V4        V5        V6  \\\n",
              "28038   0.201526 -0.403018 -0.046406  0.708998 -2.814695 -0.356957 -0.296305   \n",
              "284627  0.999005  0.101542  0.843042 -0.241025 -1.031457  1.201955  0.002530   \n",
              "237646  0.864253 -0.056813  0.712313  0.873197 -0.661824 -0.444252 -0.180090   \n",
              "234811  0.857256 -0.102864  0.707906 -0.671513  0.228768 -0.036591  0.574874   \n",
              "88119   0.358784 -0.859762  1.300495  1.143530  0.472301 -0.888677  0.550030   \n",
              "\n",
              "              V7        V8        V9  ...       V20       V21       V22  \\\n",
              "28038  -0.162918 -0.031772 -1.893162  ... -0.099445 -0.277103 -0.255063   \n",
              "284627  0.935481 -0.018998 -0.333071  ...  0.066461 -0.290075 -0.644184   \n",
              "237646 -0.895637 -2.745349  0.150701  ...  0.585094 -1.500237 -0.234961   \n",
              "234811  0.686402 -0.053521 -2.011999  ... -0.277009 -0.257745 -0.037853   \n",
              "88119  -2.072273 -5.232143 -0.467182  ...  1.225091 -2.859073 -0.121434   \n",
              "\n",
              "             V23       V24       V25       V26       V27       V28    Amount  \n",
              "28038  -0.219751 -1.051576 -0.071472 -0.318397  0.505580  0.254396 -0.097813  \n",
              "284627 -0.123625 -1.370601 -0.309764  0.202960  0.247188  0.074998 -0.271362  \n",
              "237646  0.076958  0.038061  0.451758 -0.266409  0.100812  0.267906 -0.111786  \n",
              "234811 -0.134715  0.243289 -0.568439  0.678426 -0.304572 -0.142747  1.047998  \n",
              "88119   0.072207  0.364112  1.127124  0.293169 -0.048896  0.202355 -0.028086  \n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X=new_df.drop(['Class'], axis=1)\n",
        "y=new_df['Class']\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Training set size: {X_train.shape} samples\")\n",
        "print(f\"Validation set size: {X_valid.shape} samples\")\n",
        "print(f\"Test set size: {X_test.shape} samples\")\n",
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3YyOMMvUVCU",
        "outputId": "27a1a9d8-0495-4848-f708-9229eb706037"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score of model: 0.999161710812175\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Not Fraud       1.00      1.00      1.00     28441\n",
            "       Fraud       0.80      0.70      0.75        40\n",
            "\n",
            "    accuracy                           1.00     28481\n",
            "   macro avg       0.90      0.85      0.87     28481\n",
            "weighted avg       1.00      1.00      1.00     28481\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lgm=create_logistic_regression_model(X_train,y_train)\n",
        "report(X_valid,y_valid,lgm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRtKq6-aczk5",
        "outputId": "45b87106-caf0-43a0-b652-fe7f0fce9c55"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-10-13 12:30:35.903391: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 54682800 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "7118/7121 [============================>.] - ETA: 0s - loss: 0.0566 - accuracy: 0.9818INFO:tensorflow:Assets written to: Neural_network/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Neural_network/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7121/7121 [==============================] - 12s 2ms/step - loss: 0.0566 - accuracy: 0.9818 - val_loss: 0.0027 - val_accuracy: 0.9996\n",
            "Epoch 2/5\n",
            "7121/7121 [==============================] - 10s 1ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0030 - val_accuracy: 0.9994\n",
            "Epoch 3/5\n",
            "7121/7121 [==============================] - 10s 1ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.0028 - val_accuracy: 0.9995\n",
            "Epoch 4/5\n",
            "7080/7121 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9993INFO:tensorflow:Assets written to: Neural_network/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: Neural_network/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7121/7121 [==============================] - 10s 1ms/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 0.0025 - val_accuracy: 0.9995\n",
            "Epoch 5/5\n",
            "7121/7121 [==============================] - 10s 1ms/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 0.0035 - val_accuracy: 0.9993\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f3c0cb5a950>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nn=create_neural_network(X_train)\n",
        "nn.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=5, callbacks=checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAg7WqAlg-Cl",
        "outputId": "89bff947-7128-4d21-de9b-cf83860a81c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 60/891 [=>............................] - ETA: 0s "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "891/891 [==============================] - 1s 899us/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Not Fraud       1.00      1.00      1.00     28441\n",
            "       Fraud       0.71      0.88      0.79        40\n",
            "\n",
            "    accuracy                           1.00     28481\n",
            "   macro avg       0.86      0.94      0.89     28481\n",
            "weighted avg       1.00      1.00      1.00     28481\n",
            "\n"
          ]
        }
      ],
      "source": [
        "report(X_valid,y_valid,nn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOYIe4sKkq05",
        "outputId": "a224f1d1-9566-4c91-8a25-cd743d4c7703"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Not Fraud       1.00      1.00      1.00     28441\n",
            "       Fraud       0.81      0.55      0.66        40\n",
            "\n",
            "    accuracy                           1.00     28481\n",
            "   macro avg       0.91      0.77      0.83     28481\n",
            "weighted avg       1.00      1.00      1.00     28481\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rf=create_random_forest(X_train,y_train)\n",
        "report(X_valid,y_valid,rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOyHfyaOlklo",
        "outputId": "c3450a66-48fb-42ff-c43c-bc54ad518275"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Not Fraud       1.00      1.00      1.00     28441\n",
            "       Fraud       0.78      0.72      0.75        40\n",
            "\n",
            "    accuracy                           1.00     28481\n",
            "   macro avg       0.89      0.86      0.88     28481\n",
            "weighted avg       1.00      1.00      1.00     28481\n",
            "\n"
          ]
        }
      ],
      "source": [
        "gbc=create_gradient_boosting(X_train,y_train)\n",
        "report(X_valid,y_valid,gbc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3n6PfhzsWmU",
        "outputId": "7ea8fa0a-b6eb-4933-f321-e243503e2d58"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/codespace/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Not Fraud       1.00      1.00      1.00     28441\n",
            "       Fraud       0.67      0.85      0.75        40\n",
            "\n",
            "    accuracy                           1.00     28481\n",
            "   macro avg       0.83      0.92      0.87     28481\n",
            "weighted avg       1.00      1.00      1.00     28481\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/codespace/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "svc=create_support_vector_machine(X_train,y_train)\n",
        "report(X_valid,y_valid,svc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOWMeeM8vPNM"
      },
      "source": [
        "# Creating model with balanced dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qaca7a2ivqOz",
        "outputId": "6464900c-d96f-4fad-deeb-16de75cffce4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Class\n",
              "1    492\n",
              "0    492\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fraud_df=new_df[new_df['Class']==1]\n",
        "not_fraud_df=new_df[new_df['Class']==0]\n",
        "\n",
        "# print(fraud_df.shape)\n",
        "# print(not_fraud_df.shape)\n",
        "\n",
        "balanced_df=pd.concat([fraud_df,not_fraud_df.sample(len(fraud_df),random_state=1)])\n",
        "balanced_df['Class'].value_counts()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "DsNvDqotwa27",
        "outputId": "61495e90-2677-4c31-b084-cd39eaa63c6d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>262274</th>\n",
              "      <td>0.928243</td>\n",
              "      <td>1.897000</td>\n",
              "      <td>-0.382903</td>\n",
              "      <td>-0.937501</td>\n",
              "      <td>0.397453</td>\n",
              "      <td>-0.099581</td>\n",
              "      <td>-0.147026</td>\n",
              "      <td>-0.235360</td>\n",
              "      <td>0.028097</td>\n",
              "      <td>0.502655</td>\n",
              "      <td>...</td>\n",
              "      <td>0.044393</td>\n",
              "      <td>0.114087</td>\n",
              "      <td>0.217178</td>\n",
              "      <td>0.723793</td>\n",
              "      <td>-0.250976</td>\n",
              "      <td>0.171696</td>\n",
              "      <td>-0.054108</td>\n",
              "      <td>-0.049019</td>\n",
              "      <td>0.403829</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6108</th>\n",
              "      <td>0.040430</td>\n",
              "      <td>-4.397974</td>\n",
              "      <td>1.358367</td>\n",
              "      <td>-2.592844</td>\n",
              "      <td>2.679787</td>\n",
              "      <td>-1.128131</td>\n",
              "      <td>-1.706536</td>\n",
              "      <td>-3.496197</td>\n",
              "      <td>-0.248778</td>\n",
              "      <td>-0.247768</td>\n",
              "      <td>...</td>\n",
              "      <td>0.573574</td>\n",
              "      <td>0.176968</td>\n",
              "      <td>-0.436207</td>\n",
              "      <td>-0.053502</td>\n",
              "      <td>0.252405</td>\n",
              "      <td>-0.657488</td>\n",
              "      <td>-0.827136</td>\n",
              "      <td>0.849573</td>\n",
              "      <td>0.517013</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154670</th>\n",
              "      <td>0.593135</td>\n",
              "      <td>-2.296987</td>\n",
              "      <td>4.064043</td>\n",
              "      <td>-5.957706</td>\n",
              "      <td>4.680008</td>\n",
              "      <td>-2.080938</td>\n",
              "      <td>-1.463272</td>\n",
              "      <td>-4.490847</td>\n",
              "      <td>1.029246</td>\n",
              "      <td>-1.593249</td>\n",
              "      <td>...</td>\n",
              "      <td>1.089084</td>\n",
              "      <td>0.975398</td>\n",
              "      <td>-0.625530</td>\n",
              "      <td>-0.535181</td>\n",
              "      <td>0.247435</td>\n",
              "      <td>0.160400</td>\n",
              "      <td>0.969582</td>\n",
              "      <td>0.335041</td>\n",
              "      <td>1.145812</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4405</th>\n",
              "      <td>0.021801</td>\n",
              "      <td>-0.908649</td>\n",
              "      <td>0.225291</td>\n",
              "      <td>2.065207</td>\n",
              "      <td>-1.619825</td>\n",
              "      <td>-0.243570</td>\n",
              "      <td>-0.543429</td>\n",
              "      <td>0.112440</td>\n",
              "      <td>0.029091</td>\n",
              "      <td>-0.001948</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.185273</td>\n",
              "      <td>-0.489357</td>\n",
              "      <td>0.000478</td>\n",
              "      <td>-0.029892</td>\n",
              "      <td>0.219936</td>\n",
              "      <td>-0.556919</td>\n",
              "      <td>0.238088</td>\n",
              "      <td>0.120712</td>\n",
              "      <td>0.298330</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13039</th>\n",
              "      <td>0.132535</td>\n",
              "      <td>1.293398</td>\n",
              "      <td>-0.741447</td>\n",
              "      <td>1.290535</td>\n",
              "      <td>-0.460381</td>\n",
              "      <td>-1.330159</td>\n",
              "      <td>0.323910</td>\n",
              "      <td>-1.463370</td>\n",
              "      <td>0.237573</td>\n",
              "      <td>0.988569</td>\n",
              "      <td>...</td>\n",
              "      <td>0.225547</td>\n",
              "      <td>0.976518</td>\n",
              "      <td>-0.061274</td>\n",
              "      <td>-0.002657</td>\n",
              "      <td>0.320648</td>\n",
              "      <td>-0.069984</td>\n",
              "      <td>0.035146</td>\n",
              "      <td>0.002897</td>\n",
              "      <td>-0.307413</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Time        V1        V2        V3        V4        V5        V6  \\\n",
              "262274  0.928243  1.897000 -0.382903 -0.937501  0.397453 -0.099581 -0.147026   \n",
              "6108    0.040430 -4.397974  1.358367 -2.592844  2.679787 -1.128131 -1.706536   \n",
              "154670  0.593135 -2.296987  4.064043 -5.957706  4.680008 -2.080938 -1.463272   \n",
              "4405    0.021801 -0.908649  0.225291  2.065207 -1.619825 -0.243570 -0.543429   \n",
              "13039   0.132535  1.293398 -0.741447  1.290535 -0.460381 -1.330159  0.323910   \n",
              "\n",
              "              V7        V8        V9  ...       V21       V22       V23  \\\n",
              "262274 -0.235360  0.028097  0.502655  ...  0.044393  0.114087  0.217178   \n",
              "6108   -3.496197 -0.248778 -0.247768  ...  0.573574  0.176968 -0.436207   \n",
              "154670 -4.490847  1.029246 -1.593249  ...  1.089084  0.975398 -0.625530   \n",
              "4405    0.112440  0.029091 -0.001948  ... -0.185273 -0.489357  0.000478   \n",
              "13039  -1.463370  0.237573  0.988569  ...  0.225547  0.976518 -0.061274   \n",
              "\n",
              "             V24       V25       V26       V27       V28    Amount  Class  \n",
              "262274  0.723793 -0.250976  0.171696 -0.054108 -0.049019  0.403829      0  \n",
              "6108   -0.053502  0.252405 -0.657488 -0.827136  0.849573  0.517013      1  \n",
              "154670 -0.535181  0.247435  0.160400  0.969582  0.335041  1.145812      1  \n",
              "4405   -0.029892  0.219936 -0.556919  0.238088  0.120712  0.298330      0  \n",
              "13039  -0.002657  0.320648 -0.069984  0.035146  0.002897 -0.307413      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "balanced_df = balanced_df.sample(frac=1, random_state=1)\n",
        "balanced_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "xPIxjJc6vX8T",
        "outputId": "e92bce04-de08-48e7-88cc-7e3bf6bbb08c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set size: (787, 30) samples\n",
            "Validation set size: (98, 30) samples\n",
            "Test set size: (99, 30) samples\n",
            "Class\n",
            "1    394\n",
            "0    393\n",
            "Name: count, dtype: int64\n",
            "Class\n",
            "0    54\n",
            "1    45\n",
            "Name: count, dtype: int64\n",
            "Class\n",
            "1    53\n",
            "0    45\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>96976</th>\n",
              "      <td>0.382113</td>\n",
              "      <td>-0.592714</td>\n",
              "      <td>-0.412128</td>\n",
              "      <td>1.364110</td>\n",
              "      <td>-0.764423</td>\n",
              "      <td>0.130712</td>\n",
              "      <td>-0.223794</td>\n",
              "      <td>0.185262</td>\n",
              "      <td>-0.402323</td>\n",
              "      <td>-0.828676</td>\n",
              "      <td>...</td>\n",
              "      <td>0.338200</td>\n",
              "      <td>0.159713</td>\n",
              "      <td>1.073454</td>\n",
              "      <td>-0.098848</td>\n",
              "      <td>0.295321</td>\n",
              "      <td>-0.699326</td>\n",
              "      <td>-0.274936</td>\n",
              "      <td>-0.117288</td>\n",
              "      <td>-0.099805</td>\n",
              "      <td>0.252218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186288</th>\n",
              "      <td>0.735208</td>\n",
              "      <td>1.949596</td>\n",
              "      <td>-0.577126</td>\n",
              "      <td>0.089690</td>\n",
              "      <td>0.355228</td>\n",
              "      <td>-1.070269</td>\n",
              "      <td>-0.394362</td>\n",
              "      <td>-0.900411</td>\n",
              "      <td>0.061350</td>\n",
              "      <td>1.417890</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.173994</td>\n",
              "      <td>0.038925</td>\n",
              "      <td>0.245290</td>\n",
              "      <td>0.311577</td>\n",
              "      <td>-0.061546</td>\n",
              "      <td>-0.614920</td>\n",
              "      <td>0.488492</td>\n",
              "      <td>-0.012269</td>\n",
              "      <td>-0.037644</td>\n",
              "      <td>-0.034933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198637</th>\n",
              "      <td>0.767281</td>\n",
              "      <td>2.111441</td>\n",
              "      <td>-0.096001</td>\n",
              "      <td>-2.172239</td>\n",
              "      <td>-1.005533</td>\n",
              "      <td>0.581643</td>\n",
              "      <td>-1.232151</td>\n",
              "      <td>0.603313</td>\n",
              "      <td>-0.450620</td>\n",
              "      <td>0.077968</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.080406</td>\n",
              "      <td>0.138862</td>\n",
              "      <td>0.498354</td>\n",
              "      <td>0.037848</td>\n",
              "      <td>0.878885</td>\n",
              "      <td>0.238862</td>\n",
              "      <td>0.722357</td>\n",
              "      <td>-0.130336</td>\n",
              "      <td>-0.084805</td>\n",
              "      <td>-0.120729</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177195</th>\n",
              "      <td>0.712290</td>\n",
              "      <td>-1.073820</td>\n",
              "      <td>0.415616</td>\n",
              "      <td>-2.273977</td>\n",
              "      <td>1.536844</td>\n",
              "      <td>-0.758697</td>\n",
              "      <td>-1.670381</td>\n",
              "      <td>-2.377140</td>\n",
              "      <td>0.090370</td>\n",
              "      <td>0.004847</td>\n",
              "      <td>...</td>\n",
              "      <td>0.227051</td>\n",
              "      <td>0.535542</td>\n",
              "      <td>0.863592</td>\n",
              "      <td>0.450743</td>\n",
              "      <td>-0.144228</td>\n",
              "      <td>-0.205609</td>\n",
              "      <td>-0.539073</td>\n",
              "      <td>0.503418</td>\n",
              "      <td>-0.237807</td>\n",
              "      <td>-0.153706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209012</th>\n",
              "      <td>0.795002</td>\n",
              "      <td>-0.165686</td>\n",
              "      <td>0.797939</td>\n",
              "      <td>0.659101</td>\n",
              "      <td>-0.647711</td>\n",
              "      <td>0.541264</td>\n",
              "      <td>0.306527</td>\n",
              "      <td>0.340037</td>\n",
              "      <td>-0.042117</td>\n",
              "      <td>0.421382</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.015457</td>\n",
              "      <td>0.345050</td>\n",
              "      <td>1.068582</td>\n",
              "      <td>-0.161233</td>\n",
              "      <td>0.082475</td>\n",
              "      <td>-0.745241</td>\n",
              "      <td>-0.323638</td>\n",
              "      <td>-0.001805</td>\n",
              "      <td>0.237271</td>\n",
              "      <td>-0.235311</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Time        V1        V2        V3        V4        V5        V6  \\\n",
              "96976   0.382113 -0.592714 -0.412128  1.364110 -0.764423  0.130712 -0.223794   \n",
              "186288  0.735208  1.949596 -0.577126  0.089690  0.355228 -1.070269 -0.394362   \n",
              "198637  0.767281  2.111441 -0.096001 -2.172239 -1.005533  0.581643 -1.232151   \n",
              "177195  0.712290 -1.073820  0.415616 -2.273977  1.536844 -0.758697 -1.670381   \n",
              "209012  0.795002 -0.165686  0.797939  0.659101 -0.647711  0.541264  0.306527   \n",
              "\n",
              "              V7        V8        V9  ...       V20       V21       V22  \\\n",
              "96976   0.185262 -0.402323 -0.828676  ...  0.338200  0.159713  1.073454   \n",
              "186288 -0.900411  0.061350  1.417890  ... -0.173994  0.038925  0.245290   \n",
              "198637  0.603313 -0.450620  0.077968  ... -0.080406  0.138862  0.498354   \n",
              "177195 -2.377140  0.090370  0.004847  ...  0.227051  0.535542  0.863592   \n",
              "209012  0.340037 -0.042117  0.421382  ... -0.015457  0.345050  1.068582   \n",
              "\n",
              "             V23       V24       V25       V26       V27       V28    Amount  \n",
              "96976  -0.098848  0.295321 -0.699326 -0.274936 -0.117288 -0.099805  0.252218  \n",
              "186288  0.311577 -0.061546 -0.614920  0.488492 -0.012269 -0.037644 -0.034933  \n",
              "198637  0.037848  0.878885  0.238862  0.722357 -0.130336 -0.084805 -0.120729  \n",
              "177195  0.450743 -0.144228 -0.205609 -0.539073  0.503418 -0.237807 -0.153706  \n",
              "209012 -0.161233  0.082475 -0.745241 -0.323638 -0.001805  0.237271 -0.235311  \n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X=balanced_df.drop(['Class'], axis=1)\n",
        "y=balanced_df['Class']\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Training set size: {X_train.shape} samples\")\n",
        "print(f\"Validation set size: {X_valid.shape} samples\")\n",
        "print(f\"Test set size: {X_test.shape} samples\")\n",
        "\n",
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())\n",
        "print(y_valid.value_counts())\n",
        "\n",
        "\n",
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41RpQ1nSxCfT",
        "outputId": "c4503e37-f5ea-44c6-d25b-06b283f92a74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score of model: 0.951715374841169\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Not Fraud       0.95      0.93      0.94        45\n",
            "       Fraud       0.94      0.96      0.95        53\n",
            "\n",
            "    accuracy                           0.95        98\n",
            "   macro avg       0.95      0.95      0.95        98\n",
            "weighted avg       0.95      0.95      0.95        98\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lgm_b=create_logistic_regression_model(X_train,y_train)\n",
        "report(X_valid,y_valid,lgm_b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "NABP5ib6xfVm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "25/25 [==============================] - 1s 7ms/step - loss: 0.9373 - accuracy: 0.2338 - val_loss: 1.2365 - val_accuracy: 0.2755\n",
            "Epoch 2/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.8974 - accuracy: 0.2694 - val_loss: 0.9301 - val_accuracy: 0.2959\n",
            "Epoch 3/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.8444 - accuracy: 0.3520 - val_loss: 0.7527 - val_accuracy: 0.4184\n",
            "Epoch 4/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.7414 - accuracy: 0.5210 - val_loss: 0.6562 - val_accuracy: 0.6531\n",
            "Epoch 5/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.6367 - accuracy: 0.6811 - val_loss: 0.6396 - val_accuracy: 0.7143\n",
            "Epoch 6/40\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.6110 - accuracy: 0.7141 - val_loss: 0.6248 - val_accuracy: 0.7755\n",
            "Epoch 7/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5934 - accuracy: 0.7395 - val_loss: 0.6085 - val_accuracy: 0.7857\n",
            "Epoch 8/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5758 - accuracy: 0.7598 - val_loss: 0.5915 - val_accuracy: 0.8163\n",
            "Epoch 9/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5572 - accuracy: 0.7865 - val_loss: 0.5740 - val_accuracy: 0.8469\n",
            "Epoch 10/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.5376 - accuracy: 0.8107 - val_loss: 0.5555 - val_accuracy: 0.8571\n",
            "Epoch 11/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.8259 - val_loss: 0.5361 - val_accuracy: 0.8776\n",
            "Epoch 12/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.8399 - val_loss: 0.5162 - val_accuracy: 0.8878\n",
            "Epoch 13/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.8539 - val_loss: 0.4944 - val_accuracy: 0.8878\n",
            "Epoch 14/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.8615 - val_loss: 0.4726 - val_accuracy: 0.8878\n",
            "Epoch 15/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.8780 - val_loss: 0.4503 - val_accuracy: 0.8878\n",
            "Epoch 16/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.4254 - accuracy: 0.8920 - val_loss: 0.4291 - val_accuracy: 0.8878\n",
            "Epoch 17/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.4034 - accuracy: 0.8983 - val_loss: 0.4080 - val_accuracy: 0.8878\n",
            "Epoch 18/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.3869 - accuracy: 0.9098 - val_loss: 0.3853 - val_accuracy: 0.8980\n",
            "Epoch 19/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.9149 - val_loss: 0.3633 - val_accuracy: 0.8980\n",
            "Epoch 20/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3467 - accuracy: 0.9314 - val_loss: 0.3415 - val_accuracy: 0.9286\n",
            "Epoch 21/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3185 - accuracy: 0.9301 - val_loss: 0.3221 - val_accuracy: 0.9286\n",
            "Epoch 22/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3154 - accuracy: 0.9288 - val_loss: 0.3060 - val_accuracy: 0.9286\n",
            "Epoch 23/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2937 - accuracy: 0.9352 - val_loss: 0.2909 - val_accuracy: 0.9286\n",
            "Epoch 24/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2781 - accuracy: 0.9377 - val_loss: 0.2788 - val_accuracy: 0.9286\n",
            "Epoch 25/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2761 - accuracy: 0.9327 - val_loss: 0.2688 - val_accuracy: 0.9286\n",
            "Epoch 26/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2591 - accuracy: 0.9441 - val_loss: 0.2574 - val_accuracy: 0.9286\n",
            "Epoch 27/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2521 - accuracy: 0.9377 - val_loss: 0.2481 - val_accuracy: 0.9286\n",
            "Epoch 28/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2474 - accuracy: 0.9441 - val_loss: 0.2383 - val_accuracy: 0.9286\n",
            "Epoch 29/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2287 - accuracy: 0.9466 - val_loss: 0.2327 - val_accuracy: 0.9286\n",
            "Epoch 30/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2324 - accuracy: 0.9403 - val_loss: 0.2252 - val_accuracy: 0.9286\n",
            "Epoch 31/40\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2295 - accuracy: 0.9390 - val_loss: 0.2195 - val_accuracy: 0.9286\n",
            "Epoch 32/40\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2194 - accuracy: 0.9466 - val_loss: 0.2123 - val_accuracy: 0.9286\n",
            "Epoch 33/40\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2190 - accuracy: 0.9428 - val_loss: 0.2087 - val_accuracy: 0.9388\n",
            "Epoch 34/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2086 - accuracy: 0.9441 - val_loss: 0.2039 - val_accuracy: 0.9286\n",
            "Epoch 35/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.2029 - accuracy: 0.9441 - val_loss: 0.1956 - val_accuracy: 0.9286\n",
            "Epoch 36/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1947 - accuracy: 0.9466 - val_loss: 0.1907 - val_accuracy: 0.9286\n",
            "Epoch 37/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1867 - accuracy: 0.9543 - val_loss: 0.1824 - val_accuracy: 0.9286\n",
            "Epoch 38/40\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.1876 - accuracy: 0.9479 - val_loss: 0.1766 - val_accuracy: 0.9388\n",
            "Epoch 39/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1829 - accuracy: 0.9504 - val_loss: 0.1704 - val_accuracy: 0.9286\n",
            "Epoch 40/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1846 - accuracy: 0.9530 - val_loss: 0.1641 - val_accuracy: 0.9388\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f3bece543a0>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nn_b=create_neural_network(X_train)\n",
        "nn_b.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=40, callbacks=checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "tCLy4nS5yOo2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1771 - accuracy: 0.9517 - val_loss: 0.1613 - val_accuracy: 0.9388\n",
            "Epoch 2/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1689 - accuracy: 0.9555 - val_loss: 0.1595 - val_accuracy: 0.9490\n",
            "Epoch 3/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1711 - accuracy: 0.9479 - val_loss: 0.1573 - val_accuracy: 0.9490\n",
            "Epoch 4/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1713 - accuracy: 0.9504 - val_loss: 0.1531 - val_accuracy: 0.9490\n",
            "Epoch 5/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1775 - accuracy: 0.9504 - val_loss: 0.1525 - val_accuracy: 0.9388\n",
            "Epoch 6/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1582 - accuracy: 0.9504 - val_loss: 0.1503 - val_accuracy: 0.9388\n",
            "Epoch 7/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1668 - accuracy: 0.9504 - val_loss: 0.1482 - val_accuracy: 0.9490\n",
            "Epoch 8/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1575 - accuracy: 0.9581 - val_loss: 0.1465 - val_accuracy: 0.9490\n",
            "Epoch 9/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.9568 - val_loss: 0.1440 - val_accuracy: 0.9490\n",
            "Epoch 10/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1619 - accuracy: 0.9492 - val_loss: 0.1440 - val_accuracy: 0.9490\n",
            "Epoch 11/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1559 - accuracy: 0.9543 - val_loss: 0.1457 - val_accuracy: 0.9490\n",
            "Epoch 12/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1493 - accuracy: 0.9581 - val_loss: 0.1452 - val_accuracy: 0.9388\n",
            "Epoch 13/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1630 - accuracy: 0.9543 - val_loss: 0.1447 - val_accuracy: 0.9388\n",
            "Epoch 14/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1513 - accuracy: 0.9517 - val_loss: 0.1449 - val_accuracy: 0.9388\n",
            "Epoch 15/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1486 - accuracy: 0.9517 - val_loss: 0.1473 - val_accuracy: 0.9388\n",
            "Epoch 16/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1512 - accuracy: 0.9568 - val_loss: 0.1480 - val_accuracy: 0.9388\n",
            "Epoch 17/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1468 - accuracy: 0.9606 - val_loss: 0.1513 - val_accuracy: 0.9388\n",
            "Epoch 18/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1498 - accuracy: 0.9543 - val_loss: 0.1507 - val_accuracy: 0.9388\n",
            "Epoch 19/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1553 - accuracy: 0.9555 - val_loss: 0.1523 - val_accuracy: 0.9388\n",
            "Epoch 20/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1467 - accuracy: 0.9492 - val_loss: 0.1546 - val_accuracy: 0.9388\n",
            "Epoch 21/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1538 - accuracy: 0.9543 - val_loss: 0.1530 - val_accuracy: 0.9388\n",
            "Epoch 22/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1484 - accuracy: 0.9593 - val_loss: 0.1555 - val_accuracy: 0.9388\n",
            "Epoch 23/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1404 - accuracy: 0.9606 - val_loss: 0.1561 - val_accuracy: 0.9388\n",
            "Epoch 24/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1499 - accuracy: 0.9581 - val_loss: 0.1558 - val_accuracy: 0.9388\n",
            "Epoch 25/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1341 - accuracy: 0.9606 - val_loss: 0.1554 - val_accuracy: 0.9388\n",
            "Epoch 26/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1341 - accuracy: 0.9606 - val_loss: 0.1516 - val_accuracy: 0.9388\n",
            "Epoch 27/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1459 - accuracy: 0.9543 - val_loss: 0.1557 - val_accuracy: 0.9388\n",
            "Epoch 28/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9593 - val_loss: 0.1523 - val_accuracy: 0.9388\n",
            "Epoch 29/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9543 - val_loss: 0.1553 - val_accuracy: 0.9388\n",
            "Epoch 30/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1355 - accuracy: 0.9657 - val_loss: 0.1542 - val_accuracy: 0.9388\n",
            "Epoch 31/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1387 - accuracy: 0.9581 - val_loss: 0.1555 - val_accuracy: 0.9388\n",
            "Epoch 32/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1443 - accuracy: 0.9581 - val_loss: 0.1544 - val_accuracy: 0.9388\n",
            "Epoch 33/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1334 - accuracy: 0.9606 - val_loss: 0.1564 - val_accuracy: 0.9388\n",
            "Epoch 34/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1486 - accuracy: 0.9568 - val_loss: 0.1561 - val_accuracy: 0.9388\n",
            "Epoch 35/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1360 - accuracy: 0.9619 - val_loss: 0.1580 - val_accuracy: 0.9388\n",
            "Epoch 36/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1343 - accuracy: 0.9619 - val_loss: 0.1561 - val_accuracy: 0.9388\n",
            "Epoch 37/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1395 - accuracy: 0.9593 - val_loss: 0.1580 - val_accuracy: 0.9388\n",
            "Epoch 38/40\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.1335 - accuracy: 0.9568 - val_loss: 0.1568 - val_accuracy: 0.9388\n",
            "Epoch 39/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1276 - accuracy: 0.9593 - val_loss: 0.1539 - val_accuracy: 0.9388\n",
            "Epoch 40/40\n",
            "25/25 [==============================] - 0s 2ms/step - loss: 0.1353 - accuracy: 0.9581 - val_loss: 0.1567 - val_accuracy: 0.9388\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f3bece39780>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nn_b.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=40, callbacks=checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czisHHQEycAQ",
        "outputId": "1ecab712-0260-477d-c16f-8de15aeba57c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 1ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Not Fraud       0.95      0.91      0.93        45\n",
            "       Fraud       0.93      0.96      0.94        53\n",
            "\n",
            "    accuracy                           0.94        98\n",
            "   macro avg       0.94      0.94      0.94        98\n",
            "weighted avg       0.94      0.94      0.94        98\n",
            "\n"
          ]
        }
      ],
      "source": [
        "report(X_valid,y_valid,nn_b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RxARq32yxil",
        "outputId": "4e900f38-8a25-438d-bbc5-f3cf3fce502b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Not Fraud       0.90      0.98      0.94        45\n",
            "       Fraud       0.98      0.91      0.94        53\n",
            "\n",
            "    accuracy                           0.94        98\n",
            "   macro avg       0.94      0.94      0.94        98\n",
            "weighted avg       0.94      0.94      0.94        98\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rf_b=create_random_forest(X_train,y_train)\n",
        "report(X_valid,y_valid,rf_b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAnI8w5py4s4",
        "outputId": "a22ed4d5-712b-4937-bf3f-4b3d6feb4b67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Not Fraud       0.95      0.91      0.93        45\n",
            "       Fraud       0.93      0.96      0.94        53\n",
            "\n",
            "    accuracy                           0.94        98\n",
            "   macro avg       0.94      0.94      0.94        98\n",
            "weighted avg       0.94      0.94      0.94        98\n",
            "\n"
          ]
        }
      ],
      "source": [
        "gbc_b=create_gradient_boosting(X_train,y_train)\n",
        "report(X_valid,y_valid,gbc_b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS_wWKblzEt3",
        "outputId": "28f9e55b-cfb4-4260-c83b-53f9a8898361"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Not Fraud       0.96      0.96      0.96        45\n",
            "       Fraud       0.96      0.96      0.96        53\n",
            "\n",
            "    accuracy                           0.96        98\n",
            "   macro avg       0.96      0.96      0.96        98\n",
            "weighted avg       0.96      0.96      0.96        98\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/codespace/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
            "  warnings.warn(\n",
            "/home/codespace/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "svc_b=create_support_vector_machine(X_train,y_train)\n",
        "report(X_valid,y_valid,svc_b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZRxYgW62Fhw"
      },
      "source": [
        "Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "cWFeynet1_tZ"
      },
      "outputs": [],
      "source": [
        "save_model(lgm_b)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
